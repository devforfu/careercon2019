{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import clone, BaseEstimator, TransformerMixin\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basedir import SAMPLE\n",
    "from info import id_cols\n",
    "from utils import to_feather, from_feather, starts, dropcols, float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn, y_trn, x_tst = from_feather('x_trn', 'y_trn', 'x_tst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_cluster(ser_id, feat_cols, data, k=4, normalize=True):\n",
    "    kmeans = KMeans(n_clusters=k).fit(data[feat_cols])\n",
    "    vec = kmeans.cluster_centers_.flatten()\n",
    "    return ser_id, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(data, func, **params):\n",
    "    id_col = params.get('id_col', 'series_id')\n",
    "    with joblib.Parallel(n_jobs=1, backend='loky') as parallel:\n",
    "        results = parallel(\n",
    "            joblib.delayed(func)(ser_id, dropcols(group, [id_col]), **params)\n",
    "            for ser_id, group in data.groupby(id_col))\n",
    "    _, vectors = zip(*sorted(results, key=itemgetter(0)))\n",
    "    return np.row_stack(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnsScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.scaler_ = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(float64(X[self.cols]))\n",
    "        self.scaler_ = scaler\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        allcols = X.columns\n",
    "        scaled = self.scaler_.transform(float64(X[self.cols]))\n",
    "        new = pd.DataFrame()\n",
    "        count = 0\n",
    "        for col in allcols:\n",
    "            if col not in self.cols:\n",
    "                new[col] = X[col]\n",
    "            else:\n",
    "                new[col] = scaled[:, count]\n",
    "                count += 1\n",
    "        return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, id_col, feat_cols, func=kmeans_cluster, cluster_params=None):\n",
    "        self.id_col = id_col\n",
    "        self.feat_cols = feat_cols\n",
    "        self.func = func\n",
    "        self.cluster_params = cluster_params or {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        params = self.cluster_params\n",
    "        with joblib.Parallel(n_jobs=12, backend='loky') as parallel:\n",
    "            results = parallel(\n",
    "                joblib.delayed(self.func)(self.id_col, self.feat_cols, group, **params)\n",
    "                for _, group in X.groupby(self.id_col))\n",
    "        _, vectors = zip(*sorted(results, key=itemgetter(0)))\n",
    "        return np.row_stack(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = ColumnsScaler(cols=x_trn.select_dtypes(np.float32).columns)\n",
    "x_trn_scaled = scaler.fit_transform(x_trn)\n",
    "x_tst_scaled = scaler.transform(x_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_orient = ClusterFeatures('series_id', starts(x_trn_scaled, 'orient'))\n",
    "clust_ang = ClusterFeatures('series_id', starts(x_trn_scaled, 'ang'))\n",
    "clust_lin = ClusterFeatures('series_id', starts(x_trn_scaled, 'lin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn_vec = np.column_stack([\n",
    "    clust_orient.fit_transform(x_trn_scaled),\n",
    "    clust_ang.fit_transform(x_trn_scaled),\n",
    "    clust_lin.fit_transform(x_trn_scaled)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tst_vec = np.column_stack([\n",
    "    clust_orient.fit_transform(x_tst_scaled),\n",
    "    clust_ang.fit_transform(x_tst_scaled),\n",
    "    clust_lin.fit_transform(x_tst_scaled)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "y_enc = enc.fit_transform(y_trn['surface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_trn_vec, y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_tst_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(SAMPLE)\n",
    "submit['surface'] = enc.classes_[preds]\n",
    "submit.to_csv('submit.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle c submit career-con-2019 -f 'submit.csv' -m \"One more attempt with simple clustering\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
