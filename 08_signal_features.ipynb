{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def noop(*args, **kwargs): pass\n",
    "warnings.warn = noop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import ChainMap\n",
    "from itertools import product\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tsfresh.feature_extraction.feature_calculators import *\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basedir import SAMPLE\n",
    "from info import ID_COLS\n",
    "from lightgbm_helpers import accuracy\n",
    "from utils import to_feather, from_feather, split, kfolds, replace_not_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat(f, **params):\n",
    "    def wrapper(x):\n",
    "        return f(x, **params)\n",
    "    wrapper.__name__ = f.__name__\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class StatsFeatures:\n",
    "    def __init__(self, funcs):\n",
    "        self.funcs = funcs\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        features = {}\n",
    "        for col in data.columns:\n",
    "            for func in self.funcs:\n",
    "                result = func(data[col].values)\n",
    "                if type(result) == zip:\n",
    "                    result = dict(result)\n",
    "                    for key, value in result.items():\n",
    "                        features[f'{col}__{key}'] = value\n",
    "                elif hasattr(result, '__len__'):\n",
    "                    for key, value in result:\n",
    "                        features[f'{col}__{func.__name__}__{key}'] = value\n",
    "                else:\n",
    "                    features[f'{col}__{func.__name__}'] = result\n",
    "        features = {\n",
    "            k: int(v) if v in (True, False) else v \n",
    "            for k, v in features.items()}\n",
    "        return features\n",
    "    \n",
    "class SliceFeatures:\n",
    "    def __init__(self, mode='first', n=5):\n",
    "        if mode not in {'first', 'middle', 'last'}:\n",
    "            raise ValueError('unexpected mode')\n",
    "        self.mode = mode\n",
    "        self.n = n\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        if self.mode == 'first':\n",
    "            start, end = 0, self.n\n",
    "        elif self.mode == 'last':\n",
    "            start, end = -self.n, len(data)\n",
    "        elif self.mode == 'middle':\n",
    "            mid = len(data) // 2\n",
    "            div, mod = divmod(self.n, 2)\n",
    "            start, end = mid-div, mid+div+mod\n",
    "        cols = data.columns\n",
    "        vec = data.iloc[start:end].values.T.ravel()\n",
    "        new_cols = [f'{col}_{self.mode}{i}' for i in range(self.n) for col in cols]\n",
    "        return dict(zip(new_cols, vec))\n",
    "\n",
    "    \n",
    "def add_euler_angles(X):\n",
    "    X = X.copy()\n",
    "    x, y, z, w = [X[f'orientation_{s}'] for s in list('XYZW')]\n",
    "    nx, ny, nz = quaternion_to_euler(x, y, z, w)\n",
    "    X['euler_X'] = nx\n",
    "    X['euler_Y'] = ny\n",
    "    X['euler_Z'] = nz\n",
    "    return X\n",
    "\n",
    "\n",
    "def quaternion_to_euler(x, y, z, w):\n",
    "    t0 = 2.0*(w*x + y*z)\n",
    "    t1 = 1.0 - 2.0*(x*x + y*y)\n",
    "    X = np.arctan2(t0, t1)\n",
    "    \n",
    "    t2 = np.clip(2.0*(w*y - z*x), -1, 1)\n",
    "    Y = np.arcsin(t2)\n",
    "    \n",
    "    t3 = 2.0*(w*z + x*y)\n",
    "    t4 = 1.0 - 2.0*(y*y + z*z)\n",
    "    Z = np.arctan2(t3, t4)\n",
    "    \n",
    "    return X, Y, Z\n",
    "    \n",
    "    \n",
    "def generate_features(data, features, ignore=None):\n",
    "    with Parallel(n_jobs=cpu_count()) as parallel:\n",
    "        extracted = parallel(delayed(generate_features_for_group)(\n",
    "            group=group.drop(columns=ignore or []),\n",
    "            features=features\n",
    "        ) for _, group in tqdm(data.groupby('series_id')))\n",
    "    return pd.DataFrame(extracted)\n",
    "\n",
    "\n",
    "def generate_features_for_group(group, features):\n",
    "    return dict(ChainMap(*[feat(group) for feat in features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Calculation Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = [\n",
    "    stat(fft_aggregated, param=[\n",
    "        {'aggtype': s} \n",
    "        for s in ('centroid', 'variance', 'skew', 'kurtosis')\n",
    "    ]),\n",
    "    stat(fft_coefficient, param=[\n",
    "        {'coeff': k, 'attr': a}\n",
    "        for k, a in product(range(100), ('real', 'imag', 'abs', 'angle'))\n",
    "    ]),\n",
    "    stat(cwt_coefficients, param=[\n",
    "        {'widths': width, 'coeff': coef, 'w': w}\n",
    "        for width in [(2, 5, 10, 20)]\n",
    "        for coef in range(15)\n",
    "        for w in (2, 5, 10, 20)\n",
    "    ]),\n",
    "    stat(spkt_welch_density, param=[{'coeff': k} for k in (2, 5, 8)])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_default = [\n",
    "    *[stat(time_reversal_asymmetry_statistic, lag=lag) for lag in range(1, 4)],\n",
    "    *[stat(c3, lag=lag) for lag in range(1, 4)],\n",
    "    stat(cid_ce, normalize=True), stat(cid_ce, normalize=False),\n",
    "    stat(symmetry_looking, param=[{'r': r*0.05} for r in range(1, 20)]),\n",
    "    *[stat(quantile, q=q) for q in (.1, .2, .3, .4, .6, .7, .8, .9)],\n",
    "    *[stat(autocorrelation, lag=lag) for lag in range(10)],\n",
    "    stat(agg_autocorrelation, param=[\n",
    "        {'f_agg': s, 'maxlag': 40} for s in ('mean', 'median', 'var')\n",
    "    ]),\n",
    "    stat(partial_autocorrelation, param=[\n",
    "        {'lag': lag} for lag in range(10)\n",
    "    ]),\n",
    "    *[stat(number_cwt_peaks, n=n) for n in (1, 5)],\n",
    "    *[stat(number_peaks, n=n) for n in (1, 3, 5, 10, 50)],\n",
    "    *[stat(binned_entropy, max_bins=b) for b in [10]],\n",
    "    stat(index_mass_quantile, param=[{'q': q} for q in (.1, .2, .3, .4, .6, .7, .8, .9)]),\n",
    "    stat(cwt_coefficients, param=[\n",
    "        {'widths': width, 'coeff': coeff, 'w': w}\n",
    "        for width in [(2, 5, 10, 20)]\n",
    "        for coeff in range(15)\n",
    "        for w in (2, 5, 10, 20)\n",
    "    ]),\n",
    "    stat(spkt_welch_density, param=[{'coeff': k} for k in (2, 5, 8)]),\n",
    "    stat(ar_coefficient, param=[\n",
    "        {'coeff': coeff, 'k': k} for coeff in range(5) for k in [10]\n",
    "    ]),\n",
    "    *[stat(change_quantiles, ql=ql, qh=qh, isabs=b, f_agg=f)\n",
    "        for ql in (0., .2, .4, .6, .8)\n",
    "        for qh in (.2, .4, .6, .8, 1.)\n",
    "        for b in (False, True)\n",
    "        for f in ('mean', 'var')\n",
    "    ],\n",
    "    stat(fft_aggregated, param=[\n",
    "        {'aggtype': s} \n",
    "        for s in ('centroid', 'variance', 'skew', 'kurtosis')\n",
    "    ]),\n",
    "    stat(fft_coefficient, param=[\n",
    "        {'coeff': k, 'attr': a}\n",
    "        for k, a in product(range(100), ('real', 'imag', 'abs', 'angle'))\n",
    "    ]),\n",
    "    *[stat(value_count, value=v) for v in (-1, 0, 1)],\n",
    "    *[stat(range_count, min=lo, max=hi) for lo, hi in [(-1, 1), (1e12, 0), (0, 1e12)]],\n",
    "    *[stat(approximate_entropy, m=2, r=r) for r in (.1, .3, .5, .7, .9)],\n",
    "    stat(friedrich_coefficients, param=[\n",
    "        {'coeff': coeff, 'm': 3, 'r': 30}\n",
    "        for coeff in range(4)\n",
    "    ]),\n",
    "    stat(max_langevin_fixed_point, m=3, r=30),\n",
    "    stat(linear_trend, param=[\n",
    "        {'attr': a} for a in ('pvalue', 'rvalue', 'intercept', 'slope', 'stderr')\n",
    "    ]),\n",
    "    stat(agg_linear_trend, param=[\n",
    "        {'attr': attr, 'chunk_len': i, 'f_agg': f}\n",
    "        for attr in ('rvalue', 'intercept', 'slope', 'stderr')\n",
    "        for i in (5, 10, 50)\n",
    "        for f in ('max', 'min', 'mean', 'var')\n",
    "    ]),\n",
    "    stat(augmented_dickey_fuller, param=[\n",
    "        {'attr': a} \n",
    "        for a in ('teststat', 'pvalue', 'usedlag')\n",
    "    ]),\n",
    "    *[stat(number_crossing_m, m=m) for m in (-1, 0, 1)],\n",
    "    stat(energy_ratio_by_chunks, param=[\n",
    "        {'num_segments': 10, 'segment_focus': i}\n",
    "        for i in range(10)\n",
    "    ]),\n",
    "    *[stat(ratio_beyond_r_sigma, r=r) for r in (0.5, 1, 1.5, 2, 2.5, 3, 5, 6, 7, 10)],\n",
    "    # stat(linear_trend_timewise, param=[\n",
    "    #     {'attr': a}\n",
    "    #     for a in ('pvalue', 'rvalue', 'intercept', 'slope', 'stderr')\n",
    "    # ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [StatsFeatures(funcs=funcs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending The Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn, x_tst = from_feather('x_trn', 'x_tst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols = [f'orientation_{s}' for s in list('XYZW')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn = x_trn.drop(columns=dropcols)\n",
    "x_tst = x_tst.drop(columns=dropcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ck/anaconda3/envs/fastai_10/lib/python3.7/site-packages/tsfresh/feature_extraction/feature_calculators.py:989: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return y.dot(np.arange(len(y))**moment) / y.sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3736"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, g = next(iter(x_trn.groupby('series_id')))\n",
    "len(generate_features_for_group(g, features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction on train dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabfa3b1bc7b403a948883d79d8fb2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3810), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Feature extraction on train dataset')\n",
    "x_trn_rich = (\n",
    "    replace_not_numbers(\n",
    "        generate_features(\n",
    "            data=x_trn,\n",
    "            features=features, \n",
    "            ignore=ID_COLS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction on train dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdae448067154428b27d37b584080954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3816), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Feature extraction on train dataset')\n",
    "x_tst_rich = (\n",
    "    replace_not_numbers(\n",
    "        generate_features(\n",
    "            data=x_tst,\n",
    "            features=features, \n",
    "            ignore=ID_COLS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ck/data/careercon2019/tmp/trn_rich.feather')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_feather(x_trn_rich, 'trn_rich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ck/data/careercon2019/tmp/tst_rich.feather')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_feather(x_tst_rich, 'tst_rich')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Fitting The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn, x_tst, y_trn = from_feather('trn_rich', 'tst_rich', 'y_trn')\n",
    "enc = LabelEncoder()\n",
    "y_trn = pd.Series(enc.fit_transform(y_trn['surface']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance = calculate_relevance_table(x_trn, y_trn, ml_task='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_cols = relevance[relevance['relevant']].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn = x_trn[rel_cols]\n",
    "x_tst = x_tst[rel_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    x_trn, y_trn, test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1/50\n",
      "\taccuracy improved: 56.96%\n",
      "\taccuracy improved: 61.42%\n",
      "Sample 3/50\n",
      "Sample 5/50\n",
      "\taccuracy improved: 62.47%\n",
      "Sample 9/50\n",
      "\taccuracy improved: 62.73%\n",
      "\taccuracy improved: 64.30%\n",
      "Sample 17/50\n",
      "\taccuracy improved: 64.57%\n",
      "Sample 33/50\n",
      "Sample 50/50\n"
     ]
    }
   ],
   "source": [
    "n_iter = 50\n",
    "\n",
    "base = dict(num_iterations=100, seed=seed, objective='mutliclass')\n",
    "\n",
    "sampler = ParameterSampler({\n",
    "    'boosting': ['gbdt', 'dart'],\n",
    "    'colsamples_bytree': stats.uniform(0.3, 0.7),\n",
    "    'learning_rate': stats.uniform(0.005, 0.3),\n",
    "    'num_leaves': stats.randint(31, 500),\n",
    "    'min_data_in_leaf': stats.randint(20, 50),\n",
    "    'lambda_l1': stats.uniform(0.0, 0.001),\n",
    "    'lambda_l2': stats.uniform(0.0, 0.001),\n",
    "    'drop_rate': stats.uniform(0.05, 0.3)\n",
    "}, n_iter=n_iter)\n",
    "\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "expo = 1\n",
    "\n",
    "for i, params in enumerate(sampler):\n",
    "    if i % expo == 0 or i == (n_iter - 1):\n",
    "        print(f'Sample {i+1:d}/{n_iter:d}')\n",
    "        expo *= 2\n",
    "    model = lgb.LGBMClassifier(**base, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_valid)\n",
    "    acc = (y_hat == y_valid).mean()\n",
    "    if acc > best_acc:\n",
    "        print(f'\\taccuracy improved: {acc:2.2%}')\n",
    "        best_acc = acc\n",
    "        best_params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting': 'gbdt',\n",
       " 'colsamples_bytree': 0.5495245760844689,\n",
       " 'drop_rate': 0.07859234319199895,\n",
       " 'lambda_l1': 0.00014326300616140865,\n",
       " 'lambda_l2': 0.0009310129332502252,\n",
       " 'learning_rate': 0.17797526491732218,\n",
       " 'min_data_in_leaf': 39,\n",
       " 'num_leaves': 296}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lgb.LGBMClassifier(\n",
    "#     boosting='rf', bagging_freq=1, bagging_fraction=0.66,\n",
    "#     n_estimators=1000, learning_rate=0.005,\n",
    "#     colsample_bytree=0.3, objective='multiclass',\n",
    "#     metric='None', num_leaves=200, num_class=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(num_iterations=10000, seed=seed, metric='None', **best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    eval_set=[(X_valid, y_valid)], \n",
    "    eval_metric=accuracy,\n",
    "    early_stopping_rounds=1000,\n",
    "    verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.predict(x_tst_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(SAMPLE)\n",
    "submit['surface'] = enc.inverse_transform(test)\n",
    "submit.to_csv('submit.csv', index=None)\n",
    "!kaggle c submit career-con-2019 -f 'submit.csv' -m \"10000 trees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
