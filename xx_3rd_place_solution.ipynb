{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT = Path.cwd().parent/'input'\n",
    "ROOT = Path.home()/'data'/'careercon2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = ROOT/'sample_submission.csv'\n",
    "TRAIN = ROOT/'X_train.csv'\n",
    "TARGET = ROOT/'y_train.csv'\n",
    "TEST = ROOT/'X_test.csv'\n",
    "\n",
    "ID_COLS = ['series_id', 'measurement_number']\n",
    "\n",
    "x_cols = {\n",
    "    'series_id': np.uint32,\n",
    "    'measurement_number': np.uint32,\n",
    "    'orientation_X': np.float32,\n",
    "    'orientation_Y': np.float32,\n",
    "    'orientation_Z': np.float32,\n",
    "    'orientation_W': np.float32,\n",
    "    'angular_velocity_X': np.float32,\n",
    "    'angular_velocity_Y': np.float32,\n",
    "    'angular_velocity_Z': np.float32,\n",
    "    'linear_acceleration_X': np.float32,\n",
    "    'linear_acceleration_Y': np.float32,\n",
    "    'linear_acceleration_Z': np.float32\n",
    "}\n",
    "\n",
    "y_cols = {\n",
    "    'series_id': np.uint32,\n",
    "    'group_id': np.uint32,\n",
    "    'surface': str\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn = pd.read_csv(TRAIN, usecols=x_cols.keys(), dtype=x_cols)\n",
    "x_tst = pd.read_csv(TEST, usecols=x_cols.keys(), dtype=x_cols)\n",
    "y_trn = pd.read_csv(TARGET, usecols=y_cols.keys(), dtype=y_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_euler_angles(df):\n",
    "    \"\"\"Adds Euler angles features to the dataset.\"\"\"\n",
    "    \n",
    "    x, y, z, w = [df[f'orientation_{s}'] for s in list('XYZW')]\n",
    "    nx, ny, nz = quaternion_to_euler(x, y, z, w)\n",
    "    df['euler_X'] = nx\n",
    "    df['euler_Y'] = ny\n",
    "    df['euler_Z'] = nz\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_to_euler(x, y, z, w):\n",
    "    \"\"\"Converts quaternion values into Euler angles (roll, pitch and yaw).\"\"\"\n",
    "    \n",
    "    t0 = 2.0*(w*x + y*z)\n",
    "    t1 = 1.0 - 2.0*(x*x + y*y)\n",
    "    X = np.arctan2(t0, t1)\n",
    "    \n",
    "    t2 = np.clip(2.0*(w*y - z*x), -1, 1)\n",
    "    Y = np.arcsin(t2)\n",
    "    \n",
    "    t3 = 2.0*(w*z + x*y)\n",
    "    t4 = 1.0 - 2.0*(y*y + z*z)\n",
    "    Z = np.arctan2(t3, t4)\n",
    "    \n",
    "    return X, Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startswith(df, prefix):\n",
    "    return df.columns[df.columns.str.startswith(prefix)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of series: 3810 train, 3816 test\n"
     ]
    }
   ],
   "source": [
    "trn_sz, tst_sz = x_trn.series_id.nunique(), x_tst.series_id.nunique()\n",
    "print(f'Number of series: {trn_sz} train, {tst_sz} test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tst['series_id'] += len(x_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([x_trn, x_tst], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_euler_angles(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['measurement_number'] + startswith(data, 'orient'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>243558</th>\n",
       "      <th>119111</th>\n",
       "      <th>928918</th>\n",
       "      <th>815480</th>\n",
       "      <th>249925</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>series_id</th>\n",
       "      <td>1902.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>491127.000000</td>\n",
       "      <td>490240.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <td>-0.027397</td>\n",
       "      <td>0.023170</td>\n",
       "      <td>0.129640</td>\n",
       "      <td>0.037026</td>\n",
       "      <td>-0.017861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <td>-0.038235</td>\n",
       "      <td>-0.071596</td>\n",
       "      <td>-0.003962</td>\n",
       "      <td>-0.011218</td>\n",
       "      <td>-0.045124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <td>0.141130</td>\n",
       "      <td>0.110860</td>\n",
       "      <td>0.074504</td>\n",
       "      <td>-0.085403</td>\n",
       "      <td>-0.091425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <td>0.546210</td>\n",
       "      <td>1.192700</td>\n",
       "      <td>7.679400</td>\n",
       "      <td>1.004200</td>\n",
       "      <td>-2.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <td>1.838000</td>\n",
       "      <td>1.558500</td>\n",
       "      <td>-0.908840</td>\n",
       "      <td>2.135700</td>\n",
       "      <td>2.500600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "      <td>-9.821200</td>\n",
       "      <td>-10.435000</td>\n",
       "      <td>-9.836400</td>\n",
       "      <td>-11.972000</td>\n",
       "      <td>-9.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euler_X</th>\n",
       "      <td>2.842510</td>\n",
       "      <td>2.837526</td>\n",
       "      <td>2.847498</td>\n",
       "      <td>2.842665</td>\n",
       "      <td>2.841162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euler_Y</th>\n",
       "      <td>-0.009827</td>\n",
       "      <td>-0.012305</td>\n",
       "      <td>-0.018179</td>\n",
       "      <td>-0.017390</td>\n",
       "      <td>-0.011367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euler_Z</th>\n",
       "      <td>-1.595382</td>\n",
       "      <td>-1.796759</td>\n",
       "      <td>1.863175</td>\n",
       "      <td>-3.101702</td>\n",
       "      <td>-0.247120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            243558      119111         928918         815480  \\\n",
       "series_id              1902.000000  930.000000  491127.000000  490240.000000   \n",
       "angular_velocity_X       -0.027397    0.023170       0.129640       0.037026   \n",
       "angular_velocity_Y       -0.038235   -0.071596      -0.003962      -0.011218   \n",
       "angular_velocity_Z        0.141130    0.110860       0.074504      -0.085403   \n",
       "linear_acceleration_X     0.546210    1.192700       7.679400       1.004200   \n",
       "linear_acceleration_Y     1.838000    1.558500      -0.908840       2.135700   \n",
       "linear_acceleration_Z    -9.821200  -10.435000      -9.836400     -11.972000   \n",
       "euler_X                   2.842510    2.837526       2.847498       2.842665   \n",
       "euler_Y                  -0.009827   -0.012305      -0.018179      -0.017390   \n",
       "euler_Z                  -1.595382   -1.796759       1.863175      -3.101702   \n",
       "\n",
       "                            249925  \n",
       "series_id              1952.000000  \n",
       "angular_velocity_X       -0.017861  \n",
       "angular_velocity_Y       -0.045124  \n",
       "angular_velocity_Z       -0.091425  \n",
       "linear_acceleration_X    -2.370200  \n",
       "linear_acceleration_Y     2.500600  \n",
       "linear_acceleration_Z    -9.029200  \n",
       "euler_X                   2.841162  \n",
       "euler_Y                  -0.011367  \n",
       "euler_Z                  -0.247120  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "euler_cols = startswith(data, 'euler')\n",
    "linear_cols = startswith(data, 'linear') \n",
    "angular_cols = startswith(data, 'angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_fft(arr): return np.abs(np.fft.rfft(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_mean(x): return x - x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(x): return (x - x.mean())/x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = data.groupby('series_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([\n",
    "    groups[euler_cols].diff().fillna(0),\n",
    "    groups[linear_cols].transform(zero_mean),\n",
    "    groups[angular_cols].transform(zero_mean)\n",
    "], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_data = (\n",
    "    groups[linear_cols + angular_cols]\n",
    "    .apply(lambda df: df.apply(abs_fft, axis=0))\n",
    "    .reset_index('series_id', drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "fft_seq_len = seq_len//2 + 1\n",
    "num_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared datasets shapes: (7626, 9, 128) raw, (7626, 6, 65) fft\n"
     ]
    }
   ],
   "source": [
    "# Shape of array: (batch, features, time dimension)\n",
    "raw_arr = data.values.reshape([trn_sz + tst_sz, len(data.columns),  seq_len])\n",
    "fft_arr = fft_data.values.reshape([trn_sz + tst_sz, len(fft_data.columns), fft_seq_len])\n",
    "print(f'Prepared datasets shapes: {raw_arr.shape} raw, {fft_arr.shape} fft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder().fit(y_trn['surface'])\n",
    "target = list(enc.transform(y_trn['surface']))\n",
    "target += [0] * tst_sz\n",
    "target = np.array(target)\n",
    "assert len(target) == trn_sz + tst_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(data, target, train_size, valid_pct=0.1, seed=None):\n",
    "    raw, fft = data\n",
    "    assert len(raw) == len(fft)\n",
    "    sz = train_size\n",
    "    idx = np.arange(sz)\n",
    "    trn_idx, val_idx = train_test_split(\n",
    "        idx, test_size=valid_pct, random_state=seed)\n",
    "    trn_ds = TensorDataset(\n",
    "        torch.tensor(raw[:sz][trn_idx]).float(), \n",
    "        torch.tensor(fft[:sz][trn_idx]).float(), \n",
    "        torch.tensor(target[:sz][trn_idx]).long())\n",
    "    val_ds = TensorDataset(\n",
    "        torch.tensor(raw[:sz][val_idx]).float(), \n",
    "        torch.tensor(fft[:sz][val_idx]).float(), \n",
    "        torch.tensor(target[:sz][val_idx]).long())\n",
    "    tst_ds = TensorDataset(\n",
    "        torch.tensor(raw[sz:]).float(), \n",
    "        torch.tensor(fft[sz:]).float(), \n",
    "        torch.tensor(target[sz:]).long())\n",
    "    return trn_ds, val_ds, tst_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(data, bs=128, jobs=0):\n",
    "    trn_ds, val_ds, tst_ds = data\n",
    "    trn_dl = DataLoader(trn_ds, batch_size=bs, shuffle=True, num_workers=jobs)\n",
    "    val_dl = DataLoader(val_ds, batch_size=bs, shuffle=False, num_workers=jobs)\n",
    "    tst_dl = DataLoader(tst_ds, batch_size=bs, shuffle=False, num_workers=jobs)\n",
    "    return trn_dl, val_dl, tst_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = create_datasets((raw_arr, fft_arr), target, trn_sz, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn1d_drop_layer(layers, n_outputs, drop=None, bn=True, activ=nn.ReLU):\n",
    "    \"\"\"Adds batchnorm, dropout, and/or activation layer(s) \n",
    "    to the list of layers.\n",
    "    \"\"\"\n",
    "    if bn:\n",
    "        layers += [nn.BatchNorm1d(n_outputs)]\n",
    "    if activ is not None:\n",
    "        layers += [activ()]\n",
    "    if drop and 0.0 < drop < 1.0:\n",
    "        layers += [nn.Dropout(drop)]\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d(ni, no, kernel=3, stride=1, pad=0,\n",
    "           drop=None, bn=True, activ=nn.ReLU):\n",
    "    \"\"\"A 1-d convolutional layer with few additional layers on top of it.\"\"\"\n",
    "    \n",
    "    layers = [nn.Conv1d(ni, no, kernel, stride, pad, bias=not bn)]\n",
    "    return bn1d_drop_layer(layers, no, drop, bn, activ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(ni, no, drop=None, bn=True, activ=nn.ReLU):\n",
    "    \"\"\"A fully connected layer with few additional layers on top of it.\"\"\"\n",
    "    \n",
    "    layers = [nn.Linear(ni, no, bias=not bn)]\n",
    "    return bn1d_drop_layer(layers, no, drop, bn, activ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    \"\"\"Converts N-dimensional tensor into 'flat' one.\"\"\"\n",
    "\n",
    "    def __init__(self, keep_batch_dim=True):\n",
    "        super().__init__()\n",
    "        self.keep_batch_dim = keep_batch_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.keep_batch_dim:\n",
    "            return x.view(x.size(0), -1)\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesEncoder(nn.Module):\n",
    "    def __init__(self, ni, drop=.5):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            *conv1d( ni,  32, drop=drop),\n",
    "            *conv1d( 32,  64, drop=drop),\n",
    "            *conv1d( 64, 128, drop=drop),\n",
    "            *conv1d(128, 256, drop=drop),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            Flatten(),\n",
    "            nn.Dropout(drop),\n",
    "            *fc(256, 64, drop=drop),\n",
    "            *fc( 64, 64)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, raw_ni, fft_ni, no):\n",
    "        super().__init__()\n",
    "        self.raw = TimeSeriesEncoder(raw_ni)\n",
    "        self.fft = TimeSeriesEncoder(fft_ni)\n",
    "        self.out = nn.Sequential(\n",
    "            *fc(128, 64),\n",
    "            *fc( 64, no, activ=None, bn=False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, t_raw, t_fft):\n",
    "        raw_out = self.raw(t_raw)\n",
    "        fft_out = self.fft(t_fft)\n",
    "        t_in = torch.cat([raw_out, fft_out], dim=1)\n",
    "        out = self.out(t_in)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "Epoch 1 best model saved with accuracy: 16.54%\n",
      "Epoch 3 best model saved with accuracy: 16.80%\n",
      "Epoch 4 best model saved with accuracy: 17.85%\n",
      "Epoch:   5. Loss: 1.7851. Acc.: 21.78%\n",
      "Epoch 5 best model saved with accuracy: 21.78%\n",
      "Epoch 6 best model saved with accuracy: 23.62%\n",
      "Epoch 7 best model saved with accuracy: 24.67%\n",
      "Epoch 8 best model saved with accuracy: 25.98%\n",
      "Epoch:  10. Loss: 1.5258. Acc.: 25.20%\n",
      "Epoch 12 best model saved with accuracy: 28.35%\n",
      "Epoch 13 best model saved with accuracy: 29.66%\n",
      "Epoch:  15. Loss: 1.5624. Acc.: 32.28%\n",
      "Epoch 15 best model saved with accuracy: 32.28%\n",
      "Epoch:  20. Loss: 1.5961. Acc.: 33.33%\n",
      "Epoch 20 best model saved with accuracy: 33.33%\n",
      "Epoch 21 best model saved with accuracy: 34.65%\n",
      "Epoch:  25. Loss: 1.3493. Acc.: 32.81%\n",
      "Epoch 27 best model saved with accuracy: 35.96%\n",
      "Epoch 28 best model saved with accuracy: 36.75%\n",
      "Epoch:  30. Loss: 1.4824. Acc.: 35.17%\n",
      "Epoch:  35. Loss: 1.5265. Acc.: 30.97%\n",
      "Epoch:  40. Loss: 1.5317. Acc.: 32.81%\n",
      "Epoch:  45. Loss: 1.4717. Acc.: 28.35%\n",
      "Epoch:  50. Loss: 1.4578. Acc.: 30.71%\n",
      "Epoch:  55. Loss: 1.4671. Acc.: 28.61%\n",
      "Epoch:  60. Loss: 1.4424. Acc.: 31.23%\n",
      "Epoch:  65. Loss: 1.3099. Acc.: 29.66%\n",
      "Epoch:  70. Loss: 1.3378. Acc.: 30.45%\n",
      "Epoch:  75. Loss: 1.4524. Acc.: 29.40%\n",
      "Epoch:  80. Loss: 1.3684. Acc.: 29.92%\n",
      "Epoch:  85. Loss: 1.4287. Acc.: 30.45%\n",
      "Epoch:  90. Loss: 1.3447. Acc.: 32.81%\n",
      "Epoch:  95. Loss: 1.3486. Acc.: 32.02%\n",
      "Epoch: 100. Loss: 1.2635. Acc.: 31.50%\n",
      "Epoch: 105. Loss: 1.3998. Acc.: 33.60%\n",
      "Epoch: 110. Loss: 1.4787. Acc.: 31.50%\n",
      "Epoch: 115. Loss: 1.4499. Acc.: 32.28%\n",
      "Epoch: 120. Loss: 1.4287. Acc.: 32.55%\n",
      "Epoch: 125. Loss: 1.4128. Acc.: 33.07%\n",
      "Epoch: 130. Loss: 1.2721. Acc.: 31.76%\n",
      "Epoch: 135. Loss: 1.2665. Acc.: 35.17%\n",
      "Epoch: 140. Loss: 1.3243. Acc.: 32.55%\n",
      "Epoch: 145. Loss: 1.2904. Acc.: 30.97%\n",
      "Epoch: 150. Loss: 1.2162. Acc.: 32.28%\n",
      "Epoch: 155. Loss: 1.4364. Acc.: 31.76%\n",
      "Epoch: 160. Loss: 1.3873. Acc.: 34.38%\n",
      "Epoch: 165. Loss: 1.1324. Acc.: 30.97%\n",
      "Epoch: 170. Loss: 1.3525. Acc.: 30.97%\n",
      "Epoch: 175. Loss: 1.3089. Acc.: 34.38%\n",
      "Epoch: 180. Loss: 1.1969. Acc.: 34.65%\n",
      "Epoch 181 best model saved with accuracy: 37.80%\n",
      "Epoch: 185. Loss: 1.2286. Acc.: 34.65%\n",
      "Epoch: 190. Loss: 1.3487. Acc.: 31.23%\n",
      "Epoch: 195. Loss: 1.2607. Acc.: 35.70%\n",
      "Epoch: 200. Loss: 1.1589. Acc.: 33.07%\n",
      "Epoch 203 best model saved with accuracy: 38.58%\n",
      "Epoch: 205. Loss: 1.2174. Acc.: 35.96%\n",
      "Epoch: 210. Loss: 1.1739. Acc.: 35.70%\n",
      "Epoch: 215. Loss: 1.3056. Acc.: 32.55%\n",
      "Epoch: 220. Loss: 1.2118. Acc.: 33.07%\n",
      "Epoch: 225. Loss: 1.1986. Acc.: 34.38%\n",
      "Epoch: 230. Loss: 1.2365. Acc.: 33.07%\n",
      "Epoch: 235. Loss: 1.3152. Acc.: 34.38%\n",
      "Epoch: 240. Loss: 1.1053. Acc.: 35.70%\n",
      "Epoch: 245. Loss: 1.1153. Acc.: 34.65%\n",
      "Epoch: 250. Loss: 1.0629. Acc.: 35.17%\n",
      "Epoch: 255. Loss: 1.2278. Acc.: 34.65%\n",
      "Epoch: 260. Loss: 1.1808. Acc.: 35.70%\n",
      "Epoch: 265. Loss: 1.2982. Acc.: 34.12%\n",
      "Epoch: 270. Loss: 1.3244. Acc.: 34.12%\n",
      "Epoch: 275. Loss: 1.2570. Acc.: 35.43%\n",
      "Epoch: 280. Loss: 1.0960. Acc.: 33.60%\n",
      "Epoch: 285. Loss: 1.3863. Acc.: 35.70%\n",
      "Epoch: 290. Loss: 1.2265. Acc.: 34.91%\n",
      "Epoch: 295. Loss: 1.0286. Acc.: 33.33%\n",
      "Epoch: 300. Loss: 1.2208. Acc.: 34.91%\n",
      "Epoch: 305. Loss: 1.2002. Acc.: 35.17%\n",
      "Epoch: 310. Loss: 1.2310. Acc.: 35.17%\n",
      "Epoch: 315. Loss: 1.0844. Acc.: 34.12%\n",
      "Epoch: 320. Loss: 1.0141. Acc.: 34.91%\n",
      "Epoch: 325. Loss: 1.2642. Acc.: 33.07%\n",
      "Epoch: 330. Loss: 1.1812. Acc.: 35.70%\n",
      "Epoch: 335. Loss: 1.4251. Acc.: 34.65%\n",
      "Epoch: 340. Loss: 1.1557. Acc.: 34.91%\n",
      "Epoch: 345. Loss: 1.1485. Acc.: 37.01%\n",
      "Epoch: 350. Loss: 1.0659. Acc.: 32.55%\n",
      "Epoch: 355. Loss: 1.3266. Acc.: 31.23%\n",
      "Epoch: 360. Loss: 1.0315. Acc.: 37.01%\n",
      "Epoch: 365. Loss: 1.1112. Acc.: 34.12%\n",
      "Epoch: 370. Loss: 1.0240. Acc.: 35.43%\n",
      "Epoch: 375. Loss: 1.3418. Acc.: 34.38%\n",
      "Epoch: 380. Loss: 1.2386. Acc.: 34.38%\n",
      "Epoch: 385. Loss: 1.0365. Acc.: 34.12%\n",
      "Epoch: 390. Loss: 1.0288. Acc.: 35.17%\n",
      "Epoch: 395. Loss: 1.5745. Acc.: 35.96%\n",
      "Epoch: 400. Loss: 0.9830. Acc.: 36.22%\n",
      "Epoch: 405. Loss: 1.1267. Acc.: 34.65%\n",
      "Epoch: 410. Loss: 1.1331. Acc.: 35.96%\n",
      "Epoch: 415. Loss: 1.1623. Acc.: 35.70%\n",
      "Epoch: 420. Loss: 1.1160. Acc.: 36.75%\n",
      "Epoch: 425. Loss: 1.1841. Acc.: 34.91%\n",
      "Epoch: 430. Loss: 1.1439. Acc.: 34.91%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-79d567b2b61c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_fft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_10/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_10/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raw_feat = raw_arr.shape[1]\n",
    "fft_feat = fft_arr.shape[1]\n",
    "\n",
    "trn_dl, val_dl, tst_dl = create_loaders(datasets, bs=256)\n",
    "\n",
    "lr = 0.001\n",
    "n_epochs = 3000\n",
    "iterations_per_epoch = len(trn_dl)\n",
    "best_acc = 0\n",
    "patience, trials = 500, 0\n",
    "\n",
    "model = Classifier(raw_feat, fft_feat, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "sched = CyclicLR(opt, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/100))\n",
    "\n",
    "print('Start model training')\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    model.train()\n",
    "    for i, batch in enumerate(trn_dl):\n",
    "        x_raw, x_fft, y_batch = [t.to(device) for t in batch]\n",
    "        sched.step()\n",
    "        opt.zero_grad()\n",
    "        out = model(x_raw, x_fft)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for batch in val_dl:\n",
    "        x_raw, x_fft, y_batch = [t.to(device) for t in batch]\n",
    "        out = model(x_raw, x_fft)\n",
    "        preds = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "    \n",
    "    acc = correct / total\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch: {epoch:3d}. Loss: {loss.item():.4f}. Acc.: {acc:2.2%}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        trials = 0\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'best.pth')\n",
    "        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "    else:\n",
    "        trials += 1\n",
    "        if trials >= patience:\n",
    "            print(f'Early stopping on epoch {epoch}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
