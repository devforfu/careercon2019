{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT = Path.cwd().parent/'input'\n",
    "ROOT = Path.home()/'data'/'careercon2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = ROOT/'sample_submission.csv'\n",
    "TRAIN = ROOT/'X_train.csv'\n",
    "TARGET = ROOT/'y_train.csv'\n",
    "TEST = ROOT/'X_test.csv'\n",
    "\n",
    "ID_COLS = ['series_id', 'measurement_number']\n",
    "\n",
    "x_cols = {\n",
    "    'series_id': np.uint32,\n",
    "    'measurement_number': np.uint32,\n",
    "    'orientation_X': np.float32,\n",
    "    'orientation_Y': np.float32,\n",
    "    'orientation_Z': np.float32,\n",
    "    'orientation_W': np.float32,\n",
    "    'angular_velocity_X': np.float32,\n",
    "    'angular_velocity_Y': np.float32,\n",
    "    'angular_velocity_Z': np.float32,\n",
    "    'linear_acceleration_X': np.float32,\n",
    "    'linear_acceleration_Y': np.float32,\n",
    "    'linear_acceleration_Z': np.float32\n",
    "}\n",
    "\n",
    "y_cols = {\n",
    "    'series_id': np.uint32,\n",
    "    'group_id': np.uint32,\n",
    "    'surface': str\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn = pd.read_csv(TRAIN, usecols=x_cols.keys(), dtype=x_cols)\n",
    "x_tst = pd.read_csv(TEST, usecols=x_cols.keys(), dtype=x_cols)\n",
    "y_trn = pd.read_csv(TARGET, usecols=y_cols.keys(), dtype=y_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_euler_angles(df):\n",
    "    \"\"\"Adds Euler angles features to the dataset.\"\"\"\n",
    "    \n",
    "    x, y, z, w = [df[f'orientation_{s}'] for s in list('XYZW')]\n",
    "    nx, ny, nz = quaternion_to_euler(x, y, z, w)\n",
    "    df['euler_X'] = nx\n",
    "    df['euler_Y'] = ny\n",
    "    df['euler_Z'] = nz\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_to_euler(x, y, z, w):\n",
    "    \"\"\"Converts quaternion values into Euler angles (roll, pitch and yaw).\"\"\"\n",
    "    \n",
    "    t0 = 2.0*(w*x + y*z)\n",
    "    t1 = 1.0 - 2.0*(x*x + y*y)\n",
    "    X = np.arctan2(t0, t1)\n",
    "    \n",
    "    t2 = np.clip(2.0*(w*y - z*x), -1, 1)\n",
    "    Y = np.arcsin(t2)\n",
    "    \n",
    "    t3 = 2.0*(w*z + x*y)\n",
    "    t4 = 1.0 - 2.0*(y*y + z*z)\n",
    "    Z = np.arctan2(t3, t4)\n",
    "    \n",
    "    return X, Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startswith(df, prefix):\n",
    "    return df.columns[df.columns.str.startswith(prefix)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of series: 3810 train, 3816 test\n"
     ]
    }
   ],
   "source": [
    "trn_sz, tst_sz = x_trn.series_id.nunique(), x_tst.series_id.nunique()\n",
    "print(f'Number of series: {trn_sz} train, {tst_sz} test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tst['series_id'] += len(x_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([x_trn, x_tst], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_euler_angles(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['measurement_number'] + startswith(data, 'orient'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>243558</th>\n",
       "      <th>119111</th>\n",
       "      <th>928918</th>\n",
       "      <th>815480</th>\n",
       "      <th>249925</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>series_id</th>\n",
       "      <td>1902.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>491127.000000</td>\n",
       "      <td>490240.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <td>-0.027397</td>\n",
       "      <td>0.023170</td>\n",
       "      <td>0.129640</td>\n",
       "      <td>0.037026</td>\n",
       "      <td>-0.017861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <td>-0.038235</td>\n",
       "      <td>-0.071596</td>\n",
       "      <td>-0.003962</td>\n",
       "      <td>-0.011218</td>\n",
       "      <td>-0.045124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <td>0.141130</td>\n",
       "      <td>0.110860</td>\n",
       "      <td>0.074504</td>\n",
       "      <td>-0.085403</td>\n",
       "      <td>-0.091425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <td>0.546210</td>\n",
       "      <td>1.192700</td>\n",
       "      <td>7.679400</td>\n",
       "      <td>1.004200</td>\n",
       "      <td>-2.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <td>1.838000</td>\n",
       "      <td>1.558500</td>\n",
       "      <td>-0.908840</td>\n",
       "      <td>2.135700</td>\n",
       "      <td>2.500600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "      <td>-9.821200</td>\n",
       "      <td>-10.435000</td>\n",
       "      <td>-9.836400</td>\n",
       "      <td>-11.972000</td>\n",
       "      <td>-9.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euler_X</th>\n",
       "      <td>2.842510</td>\n",
       "      <td>2.837526</td>\n",
       "      <td>2.847498</td>\n",
       "      <td>2.842665</td>\n",
       "      <td>2.841162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euler_Y</th>\n",
       "      <td>-0.009827</td>\n",
       "      <td>-0.012305</td>\n",
       "      <td>-0.018179</td>\n",
       "      <td>-0.017390</td>\n",
       "      <td>-0.011367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euler_Z</th>\n",
       "      <td>-1.595382</td>\n",
       "      <td>-1.796759</td>\n",
       "      <td>1.863175</td>\n",
       "      <td>-3.101702</td>\n",
       "      <td>-0.247120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            243558      119111         928918         815480  \\\n",
       "series_id              1902.000000  930.000000  491127.000000  490240.000000   \n",
       "angular_velocity_X       -0.027397    0.023170       0.129640       0.037026   \n",
       "angular_velocity_Y       -0.038235   -0.071596      -0.003962      -0.011218   \n",
       "angular_velocity_Z        0.141130    0.110860       0.074504      -0.085403   \n",
       "linear_acceleration_X     0.546210    1.192700       7.679400       1.004200   \n",
       "linear_acceleration_Y     1.838000    1.558500      -0.908840       2.135700   \n",
       "linear_acceleration_Z    -9.821200  -10.435000      -9.836400     -11.972000   \n",
       "euler_X                   2.842510    2.837526       2.847498       2.842665   \n",
       "euler_Y                  -0.009827   -0.012305      -0.018179      -0.017390   \n",
       "euler_Z                  -1.595382   -1.796759       1.863175      -3.101702   \n",
       "\n",
       "                            249925  \n",
       "series_id              1952.000000  \n",
       "angular_velocity_X       -0.017861  \n",
       "angular_velocity_Y       -0.045124  \n",
       "angular_velocity_Z       -0.091425  \n",
       "linear_acceleration_X    -2.370200  \n",
       "linear_acceleration_Y     2.500600  \n",
       "linear_acceleration_Z    -9.029200  \n",
       "euler_X                   2.841162  \n",
       "euler_Y                  -0.011367  \n",
       "euler_Z                  -0.247120  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "euler_cols = startswith(data, 'euler')\n",
    "linear_cols = startswith(data, 'linear') \n",
    "angular_cols = startswith(data, 'angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_fft(arr): return np.abs(np.fft.rfft(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_mean(x): return x - x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(x): return (x - x.mean())/x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = data.groupby('series_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([\n",
    "    groups[euler_cols].diff().fillna(0),\n",
    "    groups[linear_cols].transform(zero_mean),\n",
    "    groups[angular_cols].transform(zero_mean)\n",
    "], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_data = (\n",
    "    groups[linear_cols + angular_cols]\n",
    "    .apply(lambda df: df.apply(abs_fft, axis=0))\n",
    "    .reset_index('series_id', drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "fft_seq_len = seq_len//2 + 1\n",
    "num_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared datasets shapes: (7626, 9, 128) raw, (7626, 6, 65) fft\n"
     ]
    }
   ],
   "source": [
    "# Shape of array: (batch, features, time dimension)\n",
    "raw_arr = data.values.reshape([trn_sz + tst_sz, len(data.columns),  seq_len])\n",
    "fft_arr = fft_data.values.reshape([trn_sz + tst_sz, len(fft_data.columns), fft_seq_len])\n",
    "print(f'Prepared datasets shapes: {raw_arr.shape} raw, {fft_arr.shape} fft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder().fit(y_trn['surface'])\n",
    "target = list(enc.transform(y_trn['surface']))\n",
    "target += [0] * tst_sz\n",
    "target = np.array(target)\n",
    "assert len(target) == trn_sz + tst_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(data, target, train_size, valid_pct=0.1, seed=None):\n",
    "    raw, fft = data\n",
    "    assert len(raw) == len(fft)\n",
    "    sz = train_size\n",
    "    idx = np.arange(sz)\n",
    "    trn_idx, val_idx = train_test_split(\n",
    "        idx, test_size=valid_pct, random_state=seed)\n",
    "    trn_ds = TensorDataset(\n",
    "        torch.tensor(raw[:sz][trn_idx]).float(), \n",
    "        torch.tensor(fft[:sz][trn_idx]).float(), \n",
    "        torch.tensor(target[:sz][trn_idx]).long())\n",
    "    val_ds = TensorDataset(\n",
    "        torch.tensor(raw[:sz][val_idx]).float(), \n",
    "        torch.tensor(fft[:sz][val_idx]).float(), \n",
    "        torch.tensor(target[:sz][val_idx]).long())\n",
    "    tst_ds = TensorDataset(\n",
    "        torch.tensor(raw[sz:]).float(), \n",
    "        torch.tensor(fft[sz:]).float(), \n",
    "        torch.tensor(target[sz:]).long())\n",
    "    return trn_ds, val_ds, tst_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(data, bs=128, jobs=0):\n",
    "    trn_ds, val_ds, tst_ds = data\n",
    "    trn_dl = DataLoader(trn_ds, batch_size=bs, shuffle=True, num_workers=jobs)\n",
    "    val_dl = DataLoader(val_ds, batch_size=bs, shuffle=False, num_workers=jobs)\n",
    "    tst_dl = DataLoader(tst_ds, batch_size=bs, shuffle=False, num_workers=jobs)\n",
    "    return trn_dl, val_dl, tst_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = create_datasets((raw_arr, fft_arr), target, trn_sz, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn1d_drop_layer(layers, n_outputs, drop=None, bn=True, activ=nn.ReLU):\n",
    "    \"\"\"Adds batchnorm, dropout, and/or activation layer(s) \n",
    "    to the list of layers.\n",
    "    \"\"\"\n",
    "    if bn:\n",
    "        layers += [nn.BatchNorm1d(n_outputs)]\n",
    "    if activ is not None:\n",
    "        layers += [activ()]\n",
    "    if drop and 0.0 < drop < 1.0:\n",
    "        layers += [nn.Dropout(drop)]\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d(ni, no, kernel=3, stride=1, pad=0,\n",
    "           drop=None, bn=True, activ=nn.ReLU):\n",
    "    \"\"\"A 1-d convolutional layer with few additional layers on top of it.\"\"\"\n",
    "    \n",
    "    layers = [nn.Conv1d(ni, no, kernel, stride, pad, bias=not bn)]\n",
    "    return bn1d_drop_layer(layers, no, drop, bn, activ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(ni, no, drop=None, bn=True, activ=nn.ReLU):\n",
    "    \"\"\"A fully connected layer with few additional layers on top of it.\"\"\"\n",
    "    \n",
    "    layers = [nn.Linear(ni, no, bias=not bn)]\n",
    "    return bn1d_drop_layer(layers, no, drop, bn, activ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv1d(nn.Module):\n",
    "    def __init__(self, ni, no):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv1d(ni, ni, kernel_size=3, padding=1, groups=ni)\n",
    "        self.pointwise = nn.Conv1d(ni, no, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    \"\"\"Converts N-dimensional tensor into 'flat' one.\"\"\"\n",
    "\n",
    "    def __init__(self, keep_batch_dim=True):\n",
    "        super().__init__()\n",
    "        self.keep_batch_dim = keep_batch_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.keep_batch_dim:\n",
    "            return x.view(x.size(0), -1)\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TimeSeriesEncoder(nn.Module):\n",
    "#     def __init__(self, ni, drop=.5):\n",
    "#         super().__init__()\n",
    "#         self.layers = nn.ModuleList([\n",
    "#             *conv1d( ni,  32, drop=drop),\n",
    "#             *conv1d( 32,  64, drop=drop),\n",
    "#             *conv1d( 64, 128, drop=drop),\n",
    "#             *conv1d(128, 256, drop=drop),\n",
    "#             nn.AdaptiveAvgPool1d(1),\n",
    "#             Flatten(),\n",
    "#             nn.Dropout(drop),\n",
    "#             *fc(256, 64, drop=drop),\n",
    "#             *fc( 64, 64)\n",
    "#         ])\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         for layer in self.layers:\n",
    "#             x = layer(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debugger(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TimeSeriesEncoder(nn.Module):\n",
    "#     def __init__(self, ni, drop=.5):\n",
    "#         super().__init__()\n",
    "#         self.layers = nn.ModuleList([\n",
    "#             nn.Conv1d(ni, 32, 8, 2, padding=3),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(drop),\n",
    "#             nn.Conv1d(32, 64, 8, 4, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(drop),\n",
    "#             nn.Conv1d(64, 128, 8, 4, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(drop),\n",
    "#             nn.Conv1d(128, 256, 8, 4, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             Flatten(),\n",
    "#             nn.Dropout(drop),\n",
    "#             nn.Linear(256, 64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(drop),\n",
    "#             nn.Linear(64, 64),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         ])\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         for layer in self.layers:\n",
    "#             x = layer(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesEncoder(nn.Module):\n",
    "    def __init__(self, conv, top, drop=.5):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for ni, no, kernel, stride, pad in conv:\n",
    "            layers += [\n",
    "                nn.Conv1d(ni, no, kernel, stride, padding=pad),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(drop)]\n",
    "        layers.append(Flatten())\n",
    "        _, in_size, *_ = conv[-1]\n",
    "        for out_size in top:\n",
    "            layers.append(nn.Dropout(drop))\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            in_size = out_size\n",
    "        self.layers = nn.Sequential(layers)\n",
    "        \n",
    "    def forward(self, x): return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, raw_ni, fft_ni, no):\n",
    "        super().__init__()\n",
    "        self.raw = TimeSeriesEncoder(conv=[\n",
    "            (raw_ni,  32, 8, 2, 3),\n",
    "            (    32,  64, 8, 4, 2),\n",
    "            (    64, 128, 8, 4, 2),\n",
    "            (   128, 256, 8, 4, 2)\n",
    "        ], top=[64, 64])\n",
    "        self.fft = TimeSeriesEncoder(conv=[\n",
    "            (fft_ni,  32, 8, 2, 4),\n",
    "            (    32,  64, 8, 2, 4),\n",
    "            (    64, 128, 8, 4, 2),\n",
    "            (   128, 128, 8, 5, 2),\n",
    "            (   128, 256, 8, 2, 3)\n",
    "        ], top=[64, 64])\n",
    "        \n",
    "        #self.out = nn.Sequential(\n",
    "        #    *fc(128, 64),\n",
    "        #    *fc( 64, no, activ=None, bn=False)\n",
    "        #)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, no)\n",
    "        )\n",
    "    \n",
    "    def forward(self, t_raw, t_fft):\n",
    "        raw_out = self.raw(t_raw)\n",
    "        fft_out = self.fft(t_fft)\n",
    "        t_in = torch.cat([raw_out, fft_out], dim=1)\n",
    "        out = self.out(t_in)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list is not a Module subclass",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-79d567b2b61c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-e0cdb91b3217>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, raw_ni, fft_ni, no)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;34m(\u001b[0m    \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;34m(\u001b[0m   \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         ], top=[64, 64])\n\u001b[0m\u001b[1;32m     10\u001b[0m         self.fft = TimeSeriesEncoder(conv=[\n\u001b[1;32m     11\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mfft_ni\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-e9307c2b1db6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, conv, top, drop)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0min_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_10/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_item_by_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_10/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36madd_module\u001b[0;34m(self, name, module)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             raise TypeError(\"{} is not a Module subclass\".format(\n\u001b[0;32m--> 173\u001b[0;31m                 torch.typename(module)))\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             raise TypeError(\"module name should be a string. Got {}\".format(\n",
      "\u001b[0;31mTypeError\u001b[0m: list is not a Module subclass"
     ]
    }
   ],
   "source": [
    "raw_feat = raw_arr.shape[1]\n",
    "fft_feat = fft_arr.shape[1]\n",
    "\n",
    "trn_dl, val_dl, tst_dl = create_loaders(datasets, bs=256)\n",
    "\n",
    "lr = 0.001\n",
    "n_epochs = 3000\n",
    "iterations_per_epoch = len(trn_dl)\n",
    "best_acc = 0\n",
    "patience, trials = 500, 0\n",
    "\n",
    "model = Classifier(raw_feat, fft_feat, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "sched = CyclicLR(opt, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/100))\n",
    "\n",
    "print('Start model training')\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    model.train()\n",
    "    for i, batch in enumerate(trn_dl):\n",
    "        x_raw, x_fft, y_batch = [t.to(device) for t in batch]\n",
    "        sched.step()\n",
    "        opt.zero_grad()\n",
    "        out = model(x_raw, x_fft)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for batch in val_dl:\n",
    "        x_raw, x_fft, y_batch = [t.to(device) for t in batch]\n",
    "        out = model(x_raw, x_fft)\n",
    "        preds = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "    \n",
    "    acc = correct / total\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch: {epoch:3d}. Loss: {loss.item():.4f}. Acc.: {acc:2.2%}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        trials = 0\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'best.pth')\n",
    "        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "    else:\n",
    "        trials += 1\n",
    "        if trials >= patience:\n",
    "            print(f'Early stopping on epoch {epoch}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
