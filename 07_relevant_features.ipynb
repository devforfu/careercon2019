{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def noop(*args, **kwargs): pass\n",
    "warnings.warn = noop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import ChainMap\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tsfresh.feature_extraction.feature_calculators import *\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basedir import SAMPLE\n",
    "from info import ID_COLS\n",
    "from lightgbm_helpers import accuracy\n",
    "from utils import to_feather, from_feather, split, kfolds, replace_not_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat(f, **params):\n",
    "    def wrapper(x):\n",
    "        return f(x, **params)\n",
    "    wrapper.__name__ = f.__name__\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class StatsFeatures:\n",
    "    def __init__(self, funcs):\n",
    "        self.funcs = funcs\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        features = {}\n",
    "        for col in data.columns:\n",
    "            for func in self.funcs:\n",
    "                result = func(data[col].values)\n",
    "                if type(result) == zip:\n",
    "                    result = dict(result)\n",
    "                    for key, value in result.items():\n",
    "                        features[f'{col}__{key}'] = value\n",
    "                elif hasattr(result, '__len__'):\n",
    "                    for key, value in result:\n",
    "                        features[f'{col}__{func.__name__}__{key}'] = value\n",
    "                else:\n",
    "                    features[f'{col}__{func.__name__}'] = result\n",
    "        features = {\n",
    "            k: int(v) if v in (True, False) else v \n",
    "            for k, v in features.items()}\n",
    "        return features\n",
    "    \n",
    "class SliceFeatures:\n",
    "    def __init__(self, mode='first', n=5):\n",
    "        if mode not in {'first', 'middle', 'last'}:\n",
    "            raise ValueError('unexpected mode')\n",
    "        self.mode = mode\n",
    "        self.n = n\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        if self.mode == 'first':\n",
    "            start, end = 0, self.n\n",
    "        elif self.mode == 'last':\n",
    "            start, end = -self.n, len(data)\n",
    "        elif self.mode == 'middle':\n",
    "            mid = len(data) // 2\n",
    "            div, mod = divmod(self.n, 2)\n",
    "            start, end = mid-div, mid+div+mod\n",
    "        cols = data.columns\n",
    "        vec = data.iloc[start:end].values.T.ravel()\n",
    "        new_cols = [f'{col}_{self.mode}{i}' for i in range(self.n) for col in cols]\n",
    "        return dict(zip(new_cols, vec))\n",
    "\n",
    "    \n",
    "def add_euler_angles(X):\n",
    "    X = X.copy()\n",
    "    x, y, z, w = [X[f'orientation_{s}'] for s in list('XYZW')]\n",
    "    nx, ny, nz = quaternion_to_euler(x, y, z, w)\n",
    "    X['euler_X'] = nx\n",
    "    X['euler_Y'] = ny\n",
    "    X['euler_Z'] = nz\n",
    "    return X\n",
    "\n",
    "\n",
    "def quaternion_to_euler(x, y, z, w):\n",
    "    t0 = 2.0*(w*x + y*z)\n",
    "    t1 = 1.0 - 2.0*(x*x + y*y)\n",
    "    X = np.arctan2(t0, t1)\n",
    "    \n",
    "    t2 = np.clip(2.0*(w*y - z*x), -1, 1)\n",
    "    Y = np.arcsin(t2)\n",
    "    \n",
    "    t3 = 2.0*(w*z + x*y)\n",
    "    t4 = 1.0 - 2.0*(y*y + z*z)\n",
    "    Z = np.arctan2(t3, t4)\n",
    "    \n",
    "    return X, Y, Z\n",
    "    \n",
    "    \n",
    "def generate_features(data, features, ignore=None):\n",
    "    with Parallel(n_jobs=cpu_count()) as parallel:\n",
    "        extracted = parallel(delayed(generate_features_for_group)(\n",
    "            group=group.drop(columns=ignore or []),\n",
    "            features=features\n",
    "        ) for _, group in tqdm(data.groupby('series_id')))\n",
    "    return pd.DataFrame(extracted)\n",
    "\n",
    "\n",
    "def generate_features_for_group(group, features):\n",
    "    return dict(ChainMap(*[feat(group) for feat in features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Calculation Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_features = [\n",
    "    StatsFeatures(funcs=(\n",
    "        mean, median, standard_deviation, variance, skewness, kurtosis, maximum, minimum,\n",
    "        mean_change, mean_abs_change, count_above_mean, count_below_mean, \n",
    "        mean_second_derivative_central, sum_of_reoccurring_data_points,\n",
    "        abs_energy, sum_values, sample_entropy, longest_strike_above_mean,\n",
    "        longest_strike_below_mean, first_location_of_minimum, first_location_of_maximum,\n",
    "        stat(partial_autocorrelation, param=[{'lag': lag} for lag in range(10)]),\n",
    "        stat(agg_autocorrelation, \n",
    "             param=[{'f_agg': s, 'maxlag': 40} for s in ('mean', 'median', 'var')]),\n",
    "        stat(linear_trend,\n",
    "             param=[{'attr': a} for a in ('pvalue', 'rvalue', 'intercept', 'slope', 'stderr')]),\n",
    "        stat(index_mass_quantile, \n",
    "             param=[{'q': q} for q in (.1, .2, .3, .4, .6, .7, .8, .9)]),\n",
    "        stat(fft_aggregated, \n",
    "             param=[{'aggtype': t} for t in ('centroid', 'variance', 'skew', 'kurtosis')]),\n",
    "        stat(symmetry_looking, param=[{'r': r*0.05} for r in range(1, 20)]),\n",
    "        *[stat(large_standard_deviation, r=r*0.05) for r in range(1, 20)],\n",
    "        *[stat(autocorrelation, lag=lag) for lag in range(1, 10)], \n",
    "        *[stat(number_peaks, n=n) for n in (1, 2, 3, 5, 7, 10, 25, 50)],\n",
    "        *[stat(c3, lag=lag) for lag in range(1, 5)],\n",
    "        *[stat(quantile, q=q) for q in (.1, .2, .3, .4, .5, .6, .7, .8, .9)],\n",
    "        *[stat(number_crossing_m, m=m) for m in (-1, 0, 1)],\n",
    "        *[stat(ratio_beyond_r_sigma, r=r) for r in (0.5, 1, 1.5, 2, 2.5, 3, 5, 6, 7, 10)],\n",
    "        *[stat(value_count, value=v) for v in (-1, 0, 1)],\n",
    "        *[stat(range_count, min=lo, max=hi) for (lo, hi) in [(-1, 1), (1e12, 0), (0, 1e12)]]\n",
    "    )), \n",
    "    SliceFeatures('first'),\n",
    "    SliceFeatures('middle'),\n",
    "    SliceFeatures('last')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending The Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn, x_tst = from_feather('x_trn', 'x_tst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, g = next(iter(x_trn.groupby('series_id')))\n",
    "# generate_features_for_group(g, chosen_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction on train dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ff791d91c44cf298a3a2408b97e86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3810), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Feature extraction on train dataset')\n",
    "x_trn_rich = (\n",
    "    replace_not_numbers(\n",
    "        generate_features(\n",
    "            data=add_euler_angles(x_trn), \n",
    "            features=chosen_features, \n",
    "            ignore=ID_COLS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction on train dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223979ea7d9d4632a90da6c6f28fc9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3816), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Feature extraction on train dataset')\n",
    "x_tst_rich = (\n",
    "    replace_not_numbers(\n",
    "        generate_features(\n",
    "            data=add_euler_angles(x_tst), \n",
    "            features=chosen_features, \n",
    "            ignore=ID_COLS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ck/data/careercon2019/tmp/trn_rich.feather')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_feather(x_trn_rich, 'trn_rich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ck/data/careercon2019/tmp/tst_rich.feather')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_feather(x_tst_rich, 'tst_rich')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Fitting The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn, x_tst, y_trn = from_feather('trn_rich', 'tst_rich', 'y_trn')\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y_trn['surface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(x_trn, y, test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(\n",
    "    n_estimators=10000, learning_rate=0.1,\n",
    "    colsample_bytree=0.4, objective='multiclass',\n",
    "    num_leaves=500, num_class=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.255882\tvalid_0's accuracy: 0.91601\n",
      "[200]\tvalid_0's multi_logloss: 0.298802\tvalid_0's accuracy: 0.926509\n",
      "[300]\tvalid_0's multi_logloss: 0.311145\tvalid_0's accuracy: 0.929134\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 0.252839\tvalid_0's accuracy: 0.918635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.4,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=10000, n_jobs=-1, num_class=9, num_leaves=500,\n",
       "        objective='multiclass', random_state=None, reg_alpha=0.0,\n",
       "        reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    eval_set=[(X_valid, y_valid)], \n",
    "    eval_metric=accuracy,\n",
    "    early_stopping_rounds=250,\n",
    "    verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 52.9k/52.9k [00:03<00:00, 14.5kB/s]\n",
      "Successfully submitted to CareerCon 2019 - Help Navigate Robots "
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv(SAMPLE)\n",
    "submit['surface'] = enc.inverse_transform(model.predict(x_tst))\n",
    "submit.to_csv('submit.csv', index=None)\n",
    "!kaggle c submit career-con-2019 -f 'submit.csv' -m \"LightGBM + fft features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
