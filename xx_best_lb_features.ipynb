{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def noop(*args, **kwargs): pass\n",
    "warnings.warn = noop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import ChainMap\n",
    "from multiprocessing import cpu_count\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import lightgbm as lgb\n",
    "from lightgbm.engine import LightGBMError\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler\n",
    "from tsfresh import extract_features, extract_relevant_features\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basedir import SAMPLE\n",
    "from utils import from_feather, to_feather, kfolds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn, y_trn, x_tst = from_feather('x_trn', 'y_trn', 'x_tst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.feature_extraction.feature_calculators import (\n",
    "    mean, median, standard_deviation, variance, skewness, kurtosis,\n",
    "    mean_abs_change, mean_change, mean_second_derivative_central, \n",
    "    quantile, autocorrelation, agg_autocorrelation, partial_autocorrelation,\n",
    "    abs_energy, count_above_mean, count_below_mean, maximum, minimum,\n",
    "    first_location_of_minimum, first_location_of_maximum, linear_trend,\n",
    "    sample_entropy, c3, \n",
    "    longest_strike_below_mean, longest_strike_above_mean, \n",
    "    number_peaks, sum_of_reoccurring_data_points, sum_values,\n",
    "    large_standard_deviation,\n",
    "    number_crossing_m, value_count, range_count,\n",
    "    # ratio_beyond_r_sigma, index_mass_quantile,\n",
    "    # symmetry_looking\n",
    ")\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat(f, **params):\n",
    "    def wrapper(x):\n",
    "        return f(x, **params)\n",
    "    wrapper.__name__ = f.__name__\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series(data, ser_id, *ser_ids):\n",
    "    ids = [ser_id] + list(ser_ids)\n",
    "    return data[data.series_id.isin(ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_stats = (\n",
    "    mean, median, standard_deviation, variance, skewness, kurtosis, maximum, minimum,\n",
    "    mean_change, mean_abs_change, count_above_mean, count_below_mean,\n",
    "    mean_second_derivative_central, sum_of_reoccurring_data_points, \n",
    "    abs_energy, sum_values, sample_entropy,\n",
    "    longest_strike_above_mean, longest_strike_below_mean,\n",
    "    first_location_of_minimum, first_location_of_maximum,\n",
    "    *[stat(large_standard_deviation, r=r*0.05) for r in range(1, 20)],\n",
    "    *[stat(autocorrelation, lag=lag) for lag in range(1, 25)], \n",
    "    *[stat(number_peaks, n=n) for n in (1, 2, 3, 5, 7, 10, 25, 50)],\n",
    "    *[stat(c3, lag=lag) for lag in range(1, 5)],\n",
    "    *[stat(quantile, q=q) for q in (.1, .2, .3, .4, .5, .6, .7, .8, .9)],\n",
    "    stat(partial_autocorrelation, param=[{'lag': lag} for lag in range(25)]),\n",
    "    stat(agg_autocorrelation, param=[{'f_agg': s, 'maxlag': 40} for s in ('mean', 'median', 'var')]),\n",
    "    stat(linear_trend, param=[\n",
    "        {'attr': a} for a in ('pvalue', 'rvalue', 'intercept', 'slope', 'stderr')]),\n",
    "    # *[stat(number_crossing_m, m=m) for m in (-1, 0, 1)],\n",
    "    # *[stat(value_count, value=v) for v in (-1, 0, 1)],\n",
    "    # *[stat(range_count, min=lo, max=hi) for lo, hi in ((-1, 1), (1e12, 0), (0, 1e12))],\n",
    "    # *[stat(ratio_beyond_r_sigma, r=r) for r in (0.5, 1, 1.5, 2, 2.5, 3, 5, 6, 7, 10)],\n",
    "    # stat(index_mass_quantile, param=[{'q': q} for q in (.1, .2, .3, .4, .5, .6, .7, .8, .9)]),\n",
    "    # stat(symmetry_looking, param=[{'r': r*0.05} for r in range(20)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_quaternion_norm(X):\n",
    "#     X = X.copy()\n",
    "#     cols = ['orientation_X', 'orientation_Y', 'orientation_Z', 'orientation_W']\n",
    "#     X['quat_norm'] = np.sum([X[col]**2 for col in cols], axis=0)\n",
    "#     X['quat_mod'] = np.sqrt(X['quat_norm'])\n",
    "#     for col in cols:\n",
    "#         axis = col.split('_')[-1]\n",
    "#         X[f'norm_{axis}'] = X[col] / X['quat_mod']\n",
    "#     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_euler_angles(X):\n",
    "    X = X.copy()\n",
    "    # x, y, z, w = [X[f'norm_{s}'] for s in list('XYZW')]\n",
    "    x, y, z, w = [X[f'orientation_{s}'] for s in list('XYZW')]\n",
    "    nx, ny, nz = quaternion_to_euler(x, y, z, w)\n",
    "    X['euler_X'] = nx\n",
    "    X['euler_Y'] = ny\n",
    "    X['euler_Z'] = nz\n",
    "    return X\n",
    "\n",
    "\n",
    "def quaternion_to_euler(x, y, z, w):\n",
    "    t0 = 2.0*(w*x + y*z)\n",
    "    t1 = 1.0 - 2.0*(x*x + y*y)\n",
    "    X = np.arctan2(t0, t1)\n",
    "    \n",
    "    t2 = np.clip(2.0*(w*y - z*x), -1, 1)\n",
    "    Y = np.arcsin(t2)\n",
    "    \n",
    "    t3 = 2.0*(w*z + x*y)\n",
    "    t4 = 1.0 - 2.0*(y*y + z*z)\n",
    "    Z = np.arctan2(t3, t4)\n",
    "    \n",
    "    return X, Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_trn = add_euler_angles(add_quaternion_norm(x_trn)).drop(columns=[\n",
    "#     'orientation_X', 'orientation_Y', 'orientation_Z', 'orientation_W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tst = add_euler_angles(add_quaternion_norm(x_tst)).drop(columns=[\n",
    "#     'orientation_X', 'orientation_Y', 'orientation_Z', 'orientation_W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsFeatures:\n",
    "    def __init__(self, funcs=default_stats):\n",
    "        self.funcs = funcs\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        features = {}\n",
    "        for col in data.columns:\n",
    "            for func in self.funcs:\n",
    "                result = func(data[col].values) \n",
    "                if hasattr(result, '__len__'):\n",
    "                    for key, value in result:\n",
    "                        features[f'{col}__{func.__name__}__{key}'] = value\n",
    "                else:\n",
    "                    features[f'{col}__{func.__name__}'] = result\n",
    "        features = {\n",
    "            k: int(v) if v in (True, False) else v \n",
    "            for k, v in features.items()}\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceFeatures:\n",
    "    def __init__(self, mode='first', n=5):\n",
    "        if mode not in {'first', 'middle', 'last'}:\n",
    "            raise ValueError('unexpected mode')\n",
    "        self.mode = mode\n",
    "        self.n = n\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        if self.mode == 'first':\n",
    "            start, end = 0, self.n\n",
    "        elif self.mode == 'last':\n",
    "            start, end = -self.n, len(data)\n",
    "        elif self.mode == 'middle':\n",
    "            mid = len(data) // 2\n",
    "            div, mod = divmod(self.n, 2)\n",
    "            start, end = mid-div, mid+div+mod\n",
    "        cols = data.columns\n",
    "        vec = data.iloc[start:end].values.T.ravel()\n",
    "        new_cols = [f'{col}_{self.mode}{i}' for i in range(self.n) for col in cols]\n",
    "        return dict(zip(new_cols, vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, group = next(iter(x_trn.groupby('series_id')))\n",
    "group = group.drop(columns=['series_id', 'measurement_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    StatsFeatures(),\n",
    "    SliceFeatures('first'),\n",
    "    SliceFeatures('middle'),\n",
    "    SliceFeatures('last')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(data, features, ignore=None):\n",
    "    with Parallel(n_jobs=cpu_count()) as parallel:\n",
    "        extracted = parallel(delayed(generate_features_for_group)(\n",
    "            group=group.drop(columns=ignore or []),\n",
    "            features=features\n",
    "        ) for _, group in tqdm(data.groupby('series_id')))\n",
    "    return pd.DataFrame(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_for_group(group, features):\n",
    "    return dict(ChainMap(*[feat(group) for feat in features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_not_numbers(data, const=0):\n",
    "    return data.fillna(const).replace(-np.inf, const).replace(+np.inf, const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_features_for_group(group, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = ['series_id', 'measurement_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction on train dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdee3b7845542c1bce66e6a8807271b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3810), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d0b0ec8d463e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_euler_angles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_trn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             ignore=ignore)))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-64165befcea2>\u001b[0m in \u001b[0;36mgenerate_features\u001b[0;34m(data, features, ignore)\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         ) for _, group in tqdm(data.groupby('series_id')))\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_10/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_10/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_10/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_10/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_10/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Feature extraction on train dataset')\n",
    "x_trn_rich = (\n",
    "    replace_not_numbers(\n",
    "        generate_features(\n",
    "            data=add_euler_angles(x_trn), \n",
    "            features=features, \n",
    "            ignore=ignore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction on train dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0f17aaf85443d78064f782c778ae64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3816), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Feature extraction on train dataset')\n",
    "x_tst_rich = (\n",
    "    replace_not_numbers(\n",
    "        generate_features(\n",
    "            data=add_euler_angles(x_tst), \n",
    "            features=features,\n",
    "            ignore=ignore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ck/data/careercon2019/tmp/trn_rich.feather')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_feather(x_trn_rich, 'trn_rich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ck/data/careercon2019/tmp/tst_rich.feather')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_feather(x_tst_rich, 'tst_rich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn_rich, x_tst_rich, y_trn = from_feather('trn_rich', 'tst_rich', 'y_trn')\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y_trn['surface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevance = calculate_relevance_table(x_trn_rich, pd.Series(y), ml_task='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_cols = relevance[relevance['relevant']].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_trn_rich = x_trn_rich[rel_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tst_rich = x_tst_rich[rel_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "#     x_trn_rich, y, test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    y_hat = y_pred.reshape(9, n).argmax(axis=0)\n",
    "    value = (y_true == y_hat).mean()\n",
    "    return 'accuracy', value, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 1/5\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[150]\tvalid_0's accuracy: 0.842037\n",
      "[300]\tvalid_0's accuracy: 0.861619\n",
      "[450]\tvalid_0's accuracy: 0.874674\n",
      "[600]\tvalid_0's accuracy: 0.882507\n",
      "[750]\tvalid_0's accuracy: 0.890339\n",
      "[900]\tvalid_0's accuracy: 0.89295\n",
      "[1050]\tvalid_0's accuracy: 0.896867\n",
      "[1200]\tvalid_0's accuracy: 0.900783\n",
      "[1350]\tvalid_0's accuracy: 0.902089\n",
      "[1500]\tvalid_0's accuracy: 0.9047\n",
      "[1650]\tvalid_0's accuracy: 0.9047\n",
      "Early stopping, best iteration is:\n",
      "[1371]\tvalid_0's accuracy: 0.9047\n",
      "Running fold 2/5\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[150]\tvalid_0's accuracy: 0.881046\n",
      "[300]\tvalid_0's accuracy: 0.89281\n",
      "[450]\tvalid_0's accuracy: 0.894118\n",
      "[600]\tvalid_0's accuracy: 0.899346\n",
      "[750]\tvalid_0's accuracy: 0.908497\n",
      "[900]\tvalid_0's accuracy: 0.909804\n",
      "[1050]\tvalid_0's accuracy: 0.909804\n",
      "[1200]\tvalid_0's accuracy: 0.911111\n",
      "[1350]\tvalid_0's accuracy: 0.915033\n",
      "[1500]\tvalid_0's accuracy: 0.918954\n",
      "[1650]\tvalid_0's accuracy: 0.918954\n",
      "[1800]\tvalid_0's accuracy: 0.918954\n",
      "[1950]\tvalid_0's accuracy: 0.921569\n",
      "[2100]\tvalid_0's accuracy: 0.921569\n",
      "Early stopping, best iteration is:\n",
      "[1938]\tvalid_0's accuracy: 0.922876\n",
      "Running fold 3/5\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[150]\tvalid_0's accuracy: 0.860892\n",
      "[300]\tvalid_0's accuracy: 0.875328\n",
      "[450]\tvalid_0's accuracy: 0.888451\n",
      "[600]\tvalid_0's accuracy: 0.895013\n",
      "[750]\tvalid_0's accuracy: 0.902887\n",
      "[900]\tvalid_0's accuracy: 0.904199\n",
      "[1050]\tvalid_0's accuracy: 0.904199\n",
      "[1200]\tvalid_0's accuracy: 0.904199\n",
      "Early stopping, best iteration is:\n",
      "[913]\tvalid_0's accuracy: 0.908136\n",
      "Running fold 4/5\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[150]\tvalid_0's accuracy: 0.864474\n",
      "[300]\tvalid_0's accuracy: 0.869737\n",
      "[450]\tvalid_0's accuracy: 0.888158\n",
      "[600]\tvalid_0's accuracy: 0.893421\n",
      "[750]\tvalid_0's accuracy: 0.898684\n",
      "[900]\tvalid_0's accuracy: 0.910526\n",
      "[1050]\tvalid_0's accuracy: 0.913158\n",
      "[1200]\tvalid_0's accuracy: 0.918421\n",
      "[1350]\tvalid_0's accuracy: 0.918421\n",
      "[1500]\tvalid_0's accuracy: 0.918421\n",
      "Early stopping, best iteration is:\n",
      "[1245]\tvalid_0's accuracy: 0.919737\n",
      "Running fold 5/5\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[150]\tvalid_0's accuracy: 0.865258\n",
      "[300]\tvalid_0's accuracy: 0.878468\n",
      "[450]\tvalid_0's accuracy: 0.88111\n",
      "[600]\tvalid_0's accuracy: 0.890357\n",
      "[750]\tvalid_0's accuracy: 0.892999\n",
      "[900]\tvalid_0's accuracy: 0.896962\n",
      "[1050]\tvalid_0's accuracy: 0.900925\n",
      "[1200]\tvalid_0's accuracy: 0.906209\n",
      "[1350]\tvalid_0's accuracy: 0.90753\n",
      "[1500]\tvalid_0's accuracy: 0.90753\n",
      "Early stopping, best iteration is:\n",
      "[1233]\tvalid_0's accuracy: 0.90753\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "test_results = np.zeros((len(x_tst_rich), 9), dtype=np.float32)\n",
    "\n",
    "for i, x_trn, x_val, y_trn, y_val in kfolds(x_trn_rich, pd.Series(y), n_splits):\n",
    "    print(f'Running fold {i+1:d}/{n_splits:d}')\n",
    "    model = lgb.LGBMClassifier(\n",
    "        num_class=9, metric='None', n_estimators=3000, \n",
    "        learning_rate=0.005, colsample_bytree=0.4, \n",
    "        objective='multiclass', num_leaves=500, \n",
    "        random_state=seed)\n",
    "    model.fit(x_trn, y_trn,\n",
    "              eval_set=[(x_val, y_val)],\n",
    "              eval_metric=accuracy,\n",
    "              early_stopping_rounds=300,\n",
    "              verbose=150)\n",
    "    test_results += model.predict_proba(x_tst_rich)\n",
    "    \n",
    "test_results /= n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 53.0k/53.0k [00:00<00:00, 48.7kB/s]\n",
      "Successfully submitted to CareerCon 2019 - Help Navigate Robots "
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv(SAMPLE)\n",
    "submit['surface'] = enc.inverse_transform(np.argmax(test_results, axis=1))\n",
    "submit.to_csv('submit.csv', index=None)\n",
    "!kaggle c submit career-con-2019 -f 'submit.csv' -m \"LightGBM features with k-fold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1/50\n",
      "\taccuracy improved: 83.20%\n",
      "\taccuracy improved: 83.73%\n",
      "Sample 3/50\n",
      "\taccuracy improved: 85.04%\n",
      "Sample 5/50\n",
      "\taccuracy improved: 91.34%\n",
      "Sample 9/50\n",
      "\taccuracy improved: 91.86%\n",
      "Sample 17/50\n",
      "\taccuracy improved: 92.39%\n",
      "Sample 33/50\n",
      "Sample 50/50\n"
     ]
    }
   ],
   "source": [
    "n_iter = 50\n",
    "\n",
    "base = dict(num_iterations=100, seed=seed)\n",
    "\n",
    "sampler = ParameterSampler({\n",
    "    'objective': ['multiclass', 'ova'],\n",
    "    'method': [\n",
    "        ('gbdt', [0.5, 0.9]),\n",
    "        ('dart', [0.5, 0.9]),\n",
    "        ('rf', ([0.5, 0.7, 0.9], [0.5, 0.9]))],\n",
    "    'learning_rate': stats.truncnorm(0.01, 0.3),\n",
    "    'num_leaves': stats.randint(31, 500),\n",
    "    'min_data_in_leaf': stats.randint(20, 50),\n",
    "    'lambda_l1': stats.truncnorm(0.0, 0.001),\n",
    "    'lambda_l2': stats.truncnorm(0.0, 0.001),\n",
    "    'drop_rate': stats.uniform(0.05, 0.3)\n",
    "}, n_iter=n_iter)\n",
    "\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "expo = 1\n",
    "\n",
    "for i, params in enumerate(sampler):\n",
    "    if i % expo == 0 or i == (n_iter - 1):\n",
    "        print(f'Sample {i+1:d}/{n_iter:d}')\n",
    "        expo *= 2\n",
    "        \n",
    "    method, special_params = params.pop('method')\n",
    "    if method == 'rf':\n",
    "        params['bagging_fraction'] = np.random.choice(special_params[0])\n",
    "        params['feature_fraction'] = np.random.uniform(*special_params[1])\n",
    "        params['bagging_freq'] = 1\n",
    "    else:\n",
    "        params['feature_fraction'] = np.random.uniform(*special_params)\n",
    "    params['boosting'] = method\n",
    "\n",
    "    model = lgb.LGBMClassifier(**base, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_valid)\n",
    "    acc = (y_hat == y_valid).mean()\n",
    "    if acc > best_acc:\n",
    "        print(f'\\taccuracy improved: {acc:2.2%}')\n",
    "        best_acc = acc\n",
    "        best_params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_params.pickle', 'wb') as file:\n",
    "    pickle.dump(best_params, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_params.pickle', 'rb') as file:\n",
    "    best_params = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drop_rate': 0.0654425698035373,\n",
       " 'lambda_l1': 0.0009196951765450926,\n",
       " 'lambda_l2': 1.1288862652355627e-05,\n",
       " 'learning_rate': 0.26082614216073113,\n",
       " 'min_data_in_leaf': 23,\n",
       " 'num_leaves': 202,\n",
       " 'objective': 'ova',\n",
       " 'feature_fraction': 0.6699632785552281,\n",
       " 'boosting': 'dart'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 1/5\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[150]\tvalid_0's accuracy: 0.912533\n",
      "[300]\tvalid_0's accuracy: 0.920366\n",
      "[450]\tvalid_0's accuracy: 0.922977\n",
      "[600]\tvalid_0's accuracy: 0.925587\n",
      "[750]\tvalid_0's accuracy: 0.924282\n",
      "Early stopping, best iteration is:\n",
      "[576]\tvalid_0's accuracy: 0.926893\n",
      "Running fold 2/5\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[150]\tvalid_0's accuracy: 0.926797\n",
      "[300]\tvalid_0's accuracy: 0.928105\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's accuracy: 0.932026\n",
      "Running fold 3/5\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[150]\tvalid_0's accuracy: 0.913386\n",
      "[300]\tvalid_0's accuracy: 0.922572\n",
      "[450]\tvalid_0's accuracy: 0.923885\n",
      "[600]\tvalid_0's accuracy: 0.922572\n",
      "[750]\tvalid_0's accuracy: 0.925197\n",
      "Early stopping, best iteration is:\n",
      "[478]\tvalid_0's accuracy: 0.927822\n",
      "Running fold 4/5\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[150]\tvalid_0's accuracy: 0.921053\n",
      "[300]\tvalid_0's accuracy: 0.919737\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's accuracy: 0.926316\n",
      "Running fold 5/5\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[150]\tvalid_0's accuracy: 0.92074\n",
      "[300]\tvalid_0's accuracy: 0.928666\n",
      "[450]\tvalid_0's accuracy: 0.928666\n",
      "[600]\tvalid_0's accuracy: 0.928666\n",
      "Early stopping, best iteration is:\n",
      "[321]\tvalid_0's accuracy: 0.931308\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "base['num_iterations'] = 30000\n",
    "test_results = np.zeros((len(x_tst_rich), 9), dtype=np.float32)\n",
    "\n",
    "for i, x_trn, x_val, y_trn, y_val in kfolds(x_trn_rich, pd.Series(y), n_splits):\n",
    "    print(f'Running fold {i+1:d}/{n_splits:d}')\n",
    "    model = lgb.LGBMClassifier(num_class=9, metric='None', **base, **best_params)\n",
    "    model.fit(x_trn, y_trn,\n",
    "              eval_set=[(x_val, y_val)],\n",
    "              eval_metric=accuracy,\n",
    "              early_stopping_rounds=300,\n",
    "              verbose=150)\n",
    "    test_results += model.predict_proba(x_tst_rich)\n",
    "    \n",
    "test_results /= n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lgb.LGBMClassifier(\n",
    "#     n_estimators=10000, learning_rate=0.1,\n",
    "#     colsample_bytree=0.4, objective='multiclass',\n",
    "#     num_leaves=500, num_class=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     X_train, y_train, \n",
    "#     eval_set=[(X_valid, y_valid)], \n",
    "#     eval_metric=accuracy,\n",
    "#     early_stopping_rounds=250,\n",
    "#     verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp = model.feature_importances_\n",
    "# idx = np.argsort(imp)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(1, 1, figsize=(8, 20))\n",
    "# ax.barh(X_train.columns[idx], imp[idx])\n",
    "# ax.set_title('Feature Importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 52.7k/52.7k [00:00<00:00, 48.9kB/s]\n",
      "Successfully submitted to CareerCon 2019 - Help Navigate Robots "
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv(SAMPLE)\n",
    "submit['surface'] = enc.inverse_transform(np.argmax(test_results, axis=1))\n",
    "submit.to_csv('submit.csv', index=None)\n",
    "!kaggle c submit career-con-2019 -f 'submit.csv' -m \"LightGBM + relevant features + kfold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
