{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def noop(*args, **kwargs): pass\n",
    "warnings.warn = noop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import ChainMap\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tsfresh import extract_features, extract_relevant_features\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basedir import SAMPLE\n",
    "from utils import from_feather, to_feather, kfolds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn, y_trn, x_tst = from_feather('x_trn', 'y_trn', 'x_tst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.feature_extraction.feature_calculators import (\n",
    "    mean, median, standard_deviation, variance, skewness, kurtosis,\n",
    "    mean_abs_change, mean_change, mean_second_derivative_central, \n",
    "    quantile, autocorrelation, agg_autocorrelation, partial_autocorrelation,\n",
    "    abs_energy, count_above_mean, count_below_mean, maximum, minimum,\n",
    "    first_location_of_minimum, first_location_of_maximum, linear_trend,\n",
    "    sample_entropy, c3, \n",
    "    longest_strike_below_mean, longest_strike_above_mean, \n",
    "    number_peaks, sum_of_reoccurring_data_points, sum_values,\n",
    "    large_standard_deviation,\n",
    "    number_crossing_m, value_count, range_count,\n",
    "    ratio_beyond_r_sigma, index_mass_quantile,\n",
    "    symmetry_looking\n",
    ")\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat(f, **params):\n",
    "    def wrapper(x):\n",
    "        return f(x, **params)\n",
    "    wrapper.__name__ = f.__name__\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series(data, ser_id, *ser_ids):\n",
    "    ids = [ser_id] + list(ser_ids)\n",
    "    return data[data.series_id.isin(ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_stats = (\n",
    "    mean, median, standard_deviation, variance, skewness, kurtosis, maximum, minimum,\n",
    "    mean_change, mean_abs_change, count_above_mean, count_below_mean,\n",
    "    mean_second_derivative_central, sum_of_reoccurring_data_points, \n",
    "    abs_energy, sum_values, sample_entropy,\n",
    "    longest_strike_above_mean, longest_strike_below_mean,\n",
    "    first_location_of_minimum, first_location_of_maximum,\n",
    "    *[stat(large_standard_deviation, r=r*0.05) for r in range(1, 20)],\n",
    "    *[stat(autocorrelation, lag=lag) for lag in range(1, 25)], \n",
    "    *[stat(number_peaks, n=n) for n in (1, 2, 3, 5, 7, 10, 25, 50)],\n",
    "    *[stat(c3, lag=lag) for lag in range(1, 5)],\n",
    "    *[stat(quantile, q=q) for q in (.1, .2, .3, .4, .5, .6, .7, .8, .9)],\n",
    "    stat(partial_autocorrelation, param=[{'lag': lag} for lag in range(25)]),\n",
    "    stat(agg_autocorrelation, param=[{'f_agg': s, 'maxlag': 40} for s in ('mean', 'median', 'var')]),\n",
    "    stat(linear_trend, param=[\n",
    "        {'attr': a} for a in ('pvalue', 'rvalue', 'intercept', 'slope', 'stderr')]),\n",
    "    *[stat(number_crossing_m, m=m) for m in (-1, 0, 1)],\n",
    "    *[stat(value_count, value=v) for v in (-1, 0, 1)],\n",
    "    *[stat(range_count, min=lo, max=hi) for lo, hi in ((-1, 1), (1e12, 0), (0, 1e12))],\n",
    "    *[stat(ratio_beyond_r_sigma, r=r) for r in (0.5, 1, 1.5, 2, 2.5, 3, 5, 6, 7, 10)],\n",
    "    stat(index_mass_quantile, param=[{'q': q} for q in (.1, .2, .3, .4, .5, .6, .7, .8, .9)]),\n",
    "    stat(symmetry_looking, param=[{'r': r*0.05} for r in range(20)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([[1, 2, 3], [4, 5, 6]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quaternion_norm(X):\n",
    "    X = X.copy()\n",
    "    cols = ['orientation_X', 'orientation_Y', 'orientation_Z', 'orientation_W']\n",
    "    X['quat_norm'] = np.sum([X[col]**2 for col in cols], axis=0)\n",
    "    X['quat_mod'] = np.sqrt(X['quat_norm'])\n",
    "    for col in cols:\n",
    "        axis = col.split('_')[-1]\n",
    "        X[f'norm_{axis}'] = X[col] / X['quat_mod']\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_euler_angles(X):\n",
    "    X = X.copy()\n",
    "    x, y, z, w = [X[f'norm_{s}'] for s in list('XYZW')]\n",
    "    nx, ny, nz = quaternion_to_euler(x, y, z, w)\n",
    "    X['euler_X'] = nx\n",
    "    X['euler_Y'] = ny\n",
    "    X['euler_Z'] = nz\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_to_euler(x, y, z, w):\n",
    "    t0 = 2.0*(w*x + y*z)\n",
    "    t1 = 1.0 - 2.0*(x*x + y*y)\n",
    "    X = np.arctan2(t0, t1)\n",
    "    \n",
    "    t2 = np.clip(2.0*(w*y - z*x), -1, 1)\n",
    "    Y = np.arcsin(t2)\n",
    "    \n",
    "    t3 = 2.0*(w*z + x*y)\n",
    "    t4 = 1.0 - 2.0*(y*y + z*z)\n",
    "    Z = np.arctan2(t3, t4)\n",
    "    \n",
    "    return X, Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn = add_euler_angles(add_quaternion_norm(x_trn)).drop(columns=[\n",
    "    'orientation_X', 'orientation_Y', 'orientation_Z', 'orientation_W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tst = add_euler_angles(add_quaternion_norm(x_tst)).drop(columns=[\n",
    "    'orientation_X', 'orientation_Y', 'orientation_Z', 'orientation_W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsFeatures:\n",
    "    def __init__(self, funcs=default_stats):\n",
    "        self.funcs = funcs\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        features = {}\n",
    "        for col in data.columns:\n",
    "            for func in self.funcs:\n",
    "                result = func(data[col].values) \n",
    "                if hasattr(result, '__len__'):\n",
    "                    for key, value in result:\n",
    "                        features[f'{col}__{func.__name__}__{key}'] = value\n",
    "                else:\n",
    "                    features[f'{col}__{func.__name__}'] = result\n",
    "        features = {\n",
    "            k: int(v) if v in (True, False) else v \n",
    "            for k, v in features.items()}\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceFeatures:\n",
    "    def __init__(self, mode='first', n=5):\n",
    "        if mode not in {'first', 'middle', 'last'}:\n",
    "            raise ValueError('unexpected mode')\n",
    "        self.mode = mode\n",
    "        self.n = n\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        if self.mode == 'first':\n",
    "            start, end = 0, self.n\n",
    "        elif self.mode == 'last':\n",
    "            start, end = -self.n, len(data)\n",
    "        elif self.mode == 'middle':\n",
    "            mid = len(data) // 2\n",
    "            div, mod = divmod(self.n, 2)\n",
    "            start, end = mid-div, mid+div+mod\n",
    "        cols = data.columns\n",
    "        vec = data.iloc[start:end].values.T.ravel()\n",
    "        new_cols = [f'{col}_{self.mode}{i}' for i in range(self.n) for col in cols]\n",
    "        return dict(zip(new_cols, vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, group = next(iter(x_trn.groupby('series_id')))\n",
    "group = group.drop(columns=['series_id', 'measurement_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    StatsFeatures(),\n",
    "    SliceFeatures('first'),\n",
    "    SliceFeatures('middle'),\n",
    "    SliceFeatures('last')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(data, features, ignore=None):\n",
    "    with Parallel(n_jobs=cpu_count()) as parallel:\n",
    "        extracted = parallel(delayed(generate_features_for_group)(\n",
    "            group=group.drop(columns=ignore or []),\n",
    "            features=features\n",
    "        ) for _, group in tqdm(data.groupby('series_id')))\n",
    "    return pd.DataFrame(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_for_group(group, features):\n",
    "    return dict(ChainMap(*[feat(group) for feat in features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_features_for_group(group, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = ['series_id', 'measurement_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction on train dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c15f6736e244b4b952a446965587dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3810), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Feature extraction on train dataset')\n",
    "x_trn_rich = generate_features(x_trn, features, ignore=ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction on train dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f09f92792344100a2bfba7e84f445d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3816), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Feature extraction on train dataset')\n",
    "x_tst_rich = generate_features(x_tst, features, ignore=ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn_rich.fillna(0, inplace=True)\n",
    "x_trn_rich.replace(-np.inf, 0, inplace=True)\n",
    "x_trn_rich.replace(+np.inf, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tst_rich.fillna(0, inplace=True)\n",
    "x_tst_rich.replace(-np.inf, 0, inplace=True)\n",
    "x_tst_rich.replace(+np.inf, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ck/data/careercon2019/tmp/trn_rich.feather')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_feather(x_trn_rich, 'trn_rich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ck/data/careercon2019/tmp/tst_rich.feather')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_feather(x_tst_rich, 'tst_rich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn_rich, x_tst_rich, y_trn = from_feather('trn_rich', 'tst_rich', 'y_trn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y_trn['surface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance = calculate_relevance_table(x_trn_rich, pd.Series(y), ml_task='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_cols = relevance[relevance['relevant']].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn_rich = x_trn_rich[rel_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tst_rich = x_tst_rich[rel_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(x_trn_rich, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    y_hat = y_pred.reshape(9, n).argmax(axis=0)\n",
    "    value = (y_true == y_hat).mean()\n",
    "    return 'accuracy', value, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(\n",
    "    n_estimators=1000, max_features='sqrt',\n",
    "    max_depth=5, min_samples_leaf=5, min_samples_split=10,\n",
    "    verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1/50\n",
      "\taccuracy improved: 49.61%\n",
      "Sample 2/50\n",
      "\taccuracy improved: 69.03%\n",
      "Sample 3/50\n",
      "Sample 4/50\n",
      "Sample 5/50\n",
      "\taccuracy improved: 91.34%\n",
      "Sample 6/50\n",
      "Sample 7/50\n",
      "Sample 8/50\n",
      "Sample 9/50\n",
      "Sample 10/50\n",
      "Sample 11/50\n",
      "Sample 12/50\n",
      "Sample 13/50\n",
      "Sample 14/50\n",
      "Sample 15/50\n",
      "Sample 16/50\n",
      "Sample 17/50\n",
      "Sample 18/50\n",
      "Sample 19/50\n",
      "Sample 20/50\n",
      "Sample 21/50\n",
      "Sample 22/50\n",
      "Sample 23/50\n",
      "Sample 24/50\n",
      "Sample 25/50\n",
      "Sample 26/50\n",
      "Sample 27/50\n",
      "Sample 28/50\n",
      "Sample 29/50\n",
      "Sample 30/50\n",
      "Sample 31/50\n",
      "Sample 32/50\n",
      "Sample 33/50\n",
      "Sample 34/50\n",
      "Sample 35/50\n",
      "Sample 36/50\n",
      "Sample 37/50\n",
      "Sample 38/50\n",
      "Sample 39/50\n",
      "Sample 40/50\n",
      "Sample 41/50\n",
      "Sample 42/50\n",
      "Sample 43/50\n",
      "Sample 44/50\n",
      "Sample 45/50\n",
      "Sample 46/50\n",
      "Sample 47/50\n",
      "Sample 48/50\n",
      "Sample 49/50\n",
      "Sample 50/50\n"
     ]
    }
   ],
   "source": [
    "n_iter = 50\n",
    "\n",
    "sampler = ParameterSampler({\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 1, 3, 5],\n",
    "    'min_samples_split': [2, 4, 0.05],\n",
    "    'min_samples_leaf': [1, 3, 0.05],\n",
    "    'max_features': [0.6, 'sqrt', 'log2'],\n",
    "}, n_iter=n_iter)\n",
    "\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "\n",
    "for i, params in enumerate(sampler):\n",
    "    print(f'Sample {i+1:d}/{n_iter:d}')\n",
    "    forest = RandomForestClassifier(n_estimators=100, random_state=seed, **params)\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_hat = forest.predict(X_valid)\n",
    "    acc = (y_hat == y_valid).mean()\n",
    "    if acc > best_acc:\n",
    "        print(f'\\taccuracy improved: {acc:2.2%}')\n",
    "        best_acc = acc\n",
    "        best_params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(\n",
    "    n_estimators=10000, learning_rate=0.1,\n",
    "    colsample_bytree=0.4, objective='multiclass',\n",
    "    num_leaves=500, num_class=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[150]\tvalid_0's multi_logloss: 1.21663\tvalid_0's accuracy: 0.834646\n",
      "[300]\tvalid_0's multi_logloss: 0.860089\tvalid_0's accuracy: 0.834646\n",
      "[450]\tvalid_0's multi_logloss: 0.671321\tvalid_0's accuracy: 0.84252\n",
      "[600]\tvalid_0's multi_logloss: 0.560852\tvalid_0's accuracy: 0.855643\n",
      "[750]\tvalid_0's multi_logloss: 0.494286\tvalid_0's accuracy: 0.858268\n",
      "[900]\tvalid_0's multi_logloss: 0.454289\tvalid_0's accuracy: 0.871391\n",
      "[1050]\tvalid_0's multi_logloss: 0.427595\tvalid_0's accuracy: 0.87664\n",
      "[1200]\tvalid_0's multi_logloss: 0.411023\tvalid_0's accuracy: 0.87664\n",
      "Early stopping, best iteration is:\n",
      "[1004]\tvalid_0's multi_logloss: 0.434309\tvalid_0's accuracy: 0.87664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.4,\n",
       "        importance_type='split', learning_rate=0.005, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=3000, n_jobs=-1, num_class=9, num_leaves=500,\n",
       "        objective='multiclass', random_state=None, reg_alpha=0.0,\n",
       "        reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    eval_set=[(X_valid, y_valid)], \n",
    "    eval_metric=accuracy,\n",
    "    early_stopping_rounds=250,\n",
    "    verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = model.feature_importances_\n",
    "idx = np.argsort(imp)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(1, 1, figsize=(8, 20))\n",
    "# ax.barh(X_train.columns[idx], imp[idx])\n",
    "# ax.set_title('Feature Importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 52.5k/52.5k [00:00<00:00, 46.9kB/s]\n",
      "Successfully submitted to CareerCon 2019 - Help Navigate Robots "
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv(SAMPLE)\n",
    "submit['surface'] = enc.inverse_transform(model.predict(x_tst_rich))\n",
    "submit.to_csv('submit.csv', index=None)\n",
    "!kaggle c submit career-con-2019 -f 'submit.csv' -m \"LightGBM tsfresh + binary features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
